{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This notebook is used to analyse the chosen combinis in detail.\n",
    "# It creates a csv file with all the evaluation restults for all 60 models for each of the tests.\n",
    "# All the tests with length, noise, starting state etc. are being analysed here.\n",
    "# Lots of statistics and plots are produced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads or creates csv file with all evaluations to safe time for next execution\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import iqr\n",
    "\n",
    "from src.main.rl.evaluation.plots.phase3_plots import (\n",
    "    plot_actions_taken,\n",
    "    plot_observations,\n",
    ")\n",
    "from src.main.rl.evaluation.phase3_evaluation import create_evaluation_df_phase3\n",
    "from src.main.rl.utils.constants import color_mapping\n",
    "\n",
    "paths = [\n",
    "    \"src/main/rl/models/scenario1/training_04_06/scenario1_ActionSpaceOption3Wrapper_ObservationOption5Wrapper_None_RewardOption2Wrapper_SAC_training_04_06\",\n",
    "    \"src/main/rl/models/scenario1/training_04_06/scenario1_ActionSpaceOption3Wrapper_ObservationOption5Wrapper_NPPAutomationWrapper_RewardOption2Wrapper_SAC_training_04_06\",\n",
    "    \"src/main/rl/models/scenario2/training_04_06/scenario2_ActionSpaceOption3Wrapper_ObservationOption5Wrapper_None_RewardOption2Wrapper_PPO_training_04_06\",\n",
    "    \"src/main/rl/models/scenario2/training_04_06/scenario2_ActionSpaceOption3Wrapper_ObservationOption4Wrapper_NPPAutomationWrapper_RewardOption2Wrapper_PPO_training_04_06\",\n",
    "    \"src/main/rl/models/scenario3/training_04_06/scenario3_ActionSpaceOption3Wrapper_ObservationOption5Wrapper_None_RewardOption2Wrapper_PPO_training_04_06\",\n",
    "    \"src/main/rl/models/scenario3/training_04_06/scenario3_ActionSpaceOption3Wrapper_ObservationOption3Wrapper_NPPAutomationWrapper_RewardOption2Wrapper_PPO_training_04_06\",\n",
    "]\n",
    "path_to_save = (\n",
    "    \"src/main/rl/evaluation/output/phase3_evaluation_results_with_new_combi1.csv\"\n",
    ")\n",
    "os.makedirs(\"src/main/rl/evaluation/output/\",exist_ok=True)\n",
    "os.makedirs(\"src/main/rl/evaluation/plot_results/\",exist_ok=True)\n",
    "\n",
    "pd.options.display.max_colwidth = 500\n",
    "df = pd.DataFrame()\n",
    "try:\n",
    "    df = pd.read_csv(path_to_save)\n",
    "except:\n",
    "    pass\n",
    "if df.empty:\n",
    "    create_evaluation_df_phase3(path_to_save, paths)\n",
    "    df = pd.read_csv(path_to_save)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistics per combination\n",
    "df_statistics_per_combination = (\n",
    "    df.drop(columns=[\"full_path\"])\n",
    "    .groupby(\n",
    "        [\n",
    "            \"combination\",\n",
    "            \"scenario\",\n",
    "            \"alg\",\n",
    "            \"action_wrapper\",\n",
    "            \"obs_wrapper\",\n",
    "            \"automation_wrapper\",\n",
    "        ],\n",
    "        dropna=False,\n",
    "    )\n",
    "    .agg([\"mean\", \"max\", \"min\", \"std\", iqr])\n",
    ")\n",
    "# Necessary to set index as alphabetical is confusing for the thesis\n",
    "df_statistics_per_combination[\"index\"] = [0, 1, 3, 2, 5, 4]\n",
    "df_statistics_per_combination = (\n",
    "    df_statistics_per_combination.reset_index()\n",
    "    .set_index([\"index\", \"combination\"])\n",
    "    .sort_index()\n",
    ")\n",
    "df_statistics_per_combination.columns = [\n",
    "    \"_\".join(a) for a in df_statistics_per_combination.columns.to_flat_index()\n",
    "]\n",
    "save_df_per_combination = df_statistics_per_combination.copy()\n",
    "df_statistics_per_combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criticality Score per combination\n",
    "cols = [item for item in df_statistics_per_combination.columns if \"criti\" in item]\n",
    "df_statistics_per_combination[cols].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOP Analysis\n",
    "from src.main.rl.evaluation.eval import evaluate_sop\n",
    "\n",
    "(\n",
    "    cum_reward_sop,\n",
    "    criticality_score_sop,\n",
    "    total_timesteps_sop,\n",
    "    actions_taken_sop,\n",
    "    obs_taken_sop,\n",
    "    info_sop,\n",
    ") = evaluate_sop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting actions and observations from the chosen combination. In this case the SOP will be compared to combination 1.\n",
    "from src.main.rl.evaluation.plots.phase3_plots import (\n",
    "    prepare_one_combination_actions_and_obs_for_analysis,\n",
    ")\n",
    "from src.main.rl.utils.constants import color_mapping\n",
    "from src.main.rl.utils.constants import (\n",
    "    scaling_factors_scenario_1,\n",
    "    action_dimensions_german,\n",
    "    obs_scaling_factors,\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "path = \"src/main/rl/models/scenario1/training_04_06/scenario1_ActionSpaceOption3Wrapper_ObservationOption5Wrapper_None_RewardOption2Wrapper_SAC_training_04_06\"\n",
    "(\n",
    "    actions_prepared,\n",
    "    obs_prepared,\n",
    "    list_of_all_actions_taken,\n",
    "    list_of_all_obs_taken,\n",
    ") = prepare_one_combination_actions_and_obs_for_analysis(path, obs_dimensions=6)\n",
    "\n",
    "for idx, item in enumerate(actions_prepared):\n",
    "    # actions are scaled in the models, so we need to rescale\n",
    "    item = item.applymap(\n",
    "        lambda x: int(round((x + 1) * (scaling_factors_scenario_1[idx] / 2)))\n",
    "    )\n",
    "    # get min, mean, max for plotting\n",
    "    actions_prepared[idx] = item.agg([\"mean\"], axis=1)\n",
    "\n",
    "for idx, item in enumerate(obs_prepared):\n",
    "    item = item.fillna(0)\n",
    "    # rescaling obs\n",
    "    item = item.applymap(\n",
    "        lambda x: int(round((x + 1) * (obs_scaling_factors[6][idx] / 2)))\n",
    "    )\n",
    "    obs_prepared[idx] = item.agg([\"mean\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actions from SOP are printed in blue and the average action taken from combi 1 is printed in grey\n",
    "y_axis_scale_actions = [[0, 100], [0, 2200], [0, 1.1], [0, 1.1], [0, 2200]]\n",
    "\n",
    "fig, ax = plot_actions_taken(\n",
    "    actions_taken_sop, \"scenario1\", y_axis_scale_actions, color=\"standard\"\n",
    ")\n",
    "[\n",
    "    ax[idx].plot(item[\"mean\"], color=color_mapping[\"grey\"])\n",
    "    for idx, item in enumerate(actions_prepared)\n",
    "]\n",
    "\n",
    "fig.savefig(\n",
    "    f\"src/main/rl/evaluation/plot_results/phase3_action_sop_combi1.png\",\n",
    "    format=\"png\",\n",
    "    dpi=300,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obs from SOP are printed in blue and the average obs taken from combi 1 is printed in grey\n",
    "y_axis_scale_obs = [[0, 1000], [0, 4000], [0, 550], [0, 8000], [0, 180], [0, 32]]\n",
    "fig, ax = plot_observations(obs_taken_sop, y_axis_scale_obs)\n",
    "[\n",
    "    ax[idx].plot(item[\"mean\"], color=color_mapping[\"grey\"])\n",
    "    for idx, item in enumerate(obs_prepared)\n",
    "]\n",
    "fig.savefig(\n",
    "    f\"src/main/rl/evaluation/plot_results/phase3_obs_sop_combi1.png\",\n",
    "    format=\"png\",\n",
    "    dpi=300,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1000 length\n",
    "# Models which have not made the 1000 steps (out of 60)\n",
    "df[df[\"episode_length_1000_timesteps\"] != 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of succesfull models doing 1000 steps per combination.\n",
    "length_1000 = (\n",
    "    df[[\"episode_length_1000_timesteps\", \"combination\"]]\n",
    "    .set_index(\"combination\")\n",
    "    .eq(1000)\n",
    "    .groupby(\"combination\")\n",
    "    .sum()\n",
    "    .transpose()\n",
    "    .sum()\n",
    "    .transpose()\n",
    "    .to_latex()\n",
    ")\n",
    "print(length_1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how often the pumps are blown in the 1000 length test\n",
    "df[\n",
    "    [\n",
    "        \"episode_length_1000_condensator_pump_blown\",\n",
    "        \"episode_length_1000_water_pump_blown\",\n",
    "    ]\n",
    "].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noise\n",
    "cols = [item for item in df_statistics_per_combination.columns if \"DelayNoise\" in item]\n",
    "df_statistics_per_combination[cols].round(2)\n",
    "# Print statistics for different noise options per combination (return)\n",
    "print(\n",
    "    df_statistics_per_combination[cols]\n",
    "    .round(2)\n",
    "    .droplevel(1)[\n",
    "        [\n",
    "            \"DelayNoiseWrapperOption1_mean\",\n",
    "            \"DelayNoiseWrapperOption1_max\",\n",
    "            \"DelayNoiseWrapperOption1_min\",\n",
    "            \"DelayNoiseWrapperOption1_std\",\n",
    "            \"DelayNoiseWrapperOption1_iqr\",\n",
    "            \"DelayNoiseWrapperOption2_mean\",\n",
    "            \"DelayNoiseWrapperOption2_max\",\n",
    "            \"DelayNoiseWrapperOption2_min\",\n",
    "            \"DelayNoiseWrapperOption2_std\",\n",
    "            \"DelayNoiseWrapperOption2_iqr\",\n",
    "        ]\n",
    "    ]\n",
    "    .transpose()\n",
    "    .to_latex()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box Plots for noise per option and per combiniation using timesteps\n",
    "def set_box_color(bp, color, idx):\n",
    "    plt.setp(bp[\"boxes\"], color=color)\n",
    "    plt.setp(bp[\"whiskers\"], color=color)\n",
    "    plt.setp(bp[\"caps\"], color=color)\n",
    "    plt.setp(bp[\"medians\"], color=color)\n",
    "    plt.setp(bp[\"caps\"], color=color)\n",
    "    plt.setp(bp[\"fliers\"], color=color)\n",
    "\n",
    "\n",
    "noise_df = df[\n",
    "    [\n",
    "        \"obs_wrapper\",\n",
    "        \"automation_wrapper\",\n",
    "        \"scenario\",\n",
    "        \"DelayNoiseWrapperOption2_timesteps\",\n",
    "        \"DelayNoiseWrapperOption1_timesteps\",\n",
    "        \"combination\",\n",
    "        \"ObservationVariesNoiseWrapper1_timesteps\",\n",
    "        \"ObservationVariesPositiveNoiseWrapper_timesteps\",\n",
    "        \"ObservationVariesNegativeNoiseWrapper_timesteps\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "order_of_col = [\n",
    "    \"ObservationVariesPositiveNoiseWrapper_timesteps\",\n",
    "    \"ObservationVariesNegativeNoiseWrapper_timesteps\",\n",
    "    \"ObservationVariesNoiseWrapper1_timesteps\",\n",
    "    \"DelayNoiseWrapperOption1_timesteps\",\n",
    "    \"DelayNoiseWrapperOption2_timesteps\",\n",
    "]\n",
    "fig, ax = plt.subplots(constrained_layout=True)\n",
    "fig.set_figwidth(14)\n",
    "\n",
    "ax1 = ax.boxplot(\n",
    "    noise_df.query(\n",
    "        \"combination=='src/main/rl/models/scenario1/training_04_06/scenario1_ActionSpaceOption3Wrapper_ObservationOption5Wrapper_None_RewardOption2Wrapper_SAC_training_04_06'\"\n",
    "    )[order_of_col],\n",
    "    positions=[0, 0.2, 0.4, 0.6, 0.8],\n",
    "    labels=[\"1a\", \"1b\", \"1c\", \"2a\", \"2b\"],\n",
    ")\n",
    "ax2 = ax.boxplot(\n",
    "    noise_df.query(\n",
    "        \"combination=='src/main/rl/models/scenario1/training_04_06/scenario1_ActionSpaceOption3Wrapper_ObservationOption5Wrapper_NPPAutomationWrapper_RewardOption2Wrapper_SAC_training_04_06'\"\n",
    "    )[order_of_col],\n",
    "    positions=[1.2, 1.4, 1.6, 1.8, 2],\n",
    "    labels=[\"1a\", \"1b\", \"1c\", \"2a\", \"2b\"],\n",
    ")\n",
    "ax3 = ax.boxplot(\n",
    "    noise_df.query(\n",
    "        \"combination=='src/main/rl/models/scenario2/training_04_06/scenario2_ActionSpaceOption3Wrapper_ObservationOption5Wrapper_None_RewardOption2Wrapper_PPO_training_04_06'\"\n",
    "    )[order_of_col],\n",
    "    positions=[2.4, 2.6, 2.8, 3, 3.2],\n",
    "    labels=[\"1a\", \"1b\", \"1c\", \"2a\", \"2b\"],\n",
    ")\n",
    "ax4 = ax.boxplot(\n",
    "    noise_df.query(\n",
    "        \"combination=='src/main/rl/models/scenario2/training_04_06/scenario2_ActionSpaceOption3Wrapper_ObservationOption4Wrapper_NPPAutomationWrapper_RewardOption2Wrapper_PPO_training_04_06'\"\n",
    "    )[order_of_col],\n",
    "    positions=[3.6, 3.8, 4, 4.2, 4.4],\n",
    "    labels=[\"1a\", \"1b\", \"1c\", \"2a\", \"2b\"],\n",
    ")\n",
    "ax5 = ax.boxplot(\n",
    "    noise_df.query(\n",
    "        \"combination=='src/main/rl/models/scenario3/training_04_06/scenario3_ActionSpaceOption3Wrapper_ObservationOption5Wrapper_None_RewardOption2Wrapper_PPO_training_04_06'\"\n",
    "    )[order_of_col],\n",
    "    positions=[4.8, 5, 5.2, 5.4, 5.6],\n",
    "    labels=[\"1a\", \"1b\", \"1c\", \"2a\", \"2b\"],\n",
    ")\n",
    "ax6 = ax.boxplot(\n",
    "    noise_df.query(\n",
    "        \"combination=='src/main/rl/models/scenario3/training_04_06/scenario3_ActionSpaceOption3Wrapper_ObservationOption3Wrapper_NPPAutomationWrapper_RewardOption2Wrapper_PPO_training_04_06'\"\n",
    "    )[order_of_col],\n",
    "    positions=[6, 6.2, 6.4, 6.6, 6.8],\n",
    "    labels=[\"1a\", \"1b\", \"1c\", \"2a\", \"2b\"],\n",
    ")\n",
    "set_box_color(ax1, color_mapping[\"blue\"], 0)\n",
    "set_box_color(ax1, color_mapping[\"blue\"], 1)\n",
    "set_box_color(ax2, color_mapping[\"red\"], 0)\n",
    "set_box_color(ax2, color_mapping[\"red\"], 1)\n",
    "set_box_color(ax3, color_mapping[\"grey\"], 0)\n",
    "set_box_color(ax3, color_mapping[\"grey\"], 1)\n",
    "set_box_color(ax4, color_mapping[\"yellow\"], 0)\n",
    "set_box_color(ax4, color_mapping[\"yellow\"], 1)\n",
    "set_box_color(ax5, color_mapping[\"brown\"], 0)\n",
    "set_box_color(ax5, color_mapping[\"brown\"], 1)\n",
    "set_box_color(ax6, color_mapping[\"turquoise\"], 0)\n",
    "set_box_color(ax6, color_mapping[\"turquoise\"], 1)\n",
    "ax.set_xlabel(\"Rauschoptionen\")\n",
    "ax.set_ylabel(\"Absolvierte Zeitschritte\")\n",
    "plt.plot([], c=color_mapping[\"blue\"], label=\"Kombination 1\")\n",
    "plt.plot([], c=color_mapping[\"red\"], label=\"Kombination 2\")\n",
    "plt.plot([], c=color_mapping[\"grey\"], label=\"Kombination 3\")\n",
    "plt.plot([], c=color_mapping[\"yellow\"], label=\"Kombination 4\")\n",
    "plt.plot([], c=color_mapping[\"brown\"], label=\"Kombination 5\")\n",
    "plt.plot([], c=color_mapping[\"turquoise\"], label=\"Kombination 6\")\n",
    "plt.legend(loc=[0.2, 0.1])\n",
    "\n",
    "plt.show()\n",
    "plt.tight_layout = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many models have successfully completed the 250 timesteps per noise option\n",
    "noise_df.eq(250).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box Plots for noise per option and per combiniation using return\n",
    "def set_box_color(bp, color, idx):\n",
    "    plt.setp(bp[\"boxes\"], color=color)\n",
    "    plt.setp(bp[\"whiskers\"], color=color)\n",
    "    plt.setp(bp[\"caps\"], color=color)\n",
    "    plt.setp(bp[\"medians\"], color=color)\n",
    "    plt.setp(bp[\"caps\"], color=color)\n",
    "    plt.setp(bp[\"fliers\"], color=color)\n",
    "\n",
    "\n",
    "noise_df = df[\n",
    "    [\n",
    "        \"obs_wrapper\",\n",
    "        \"automation_wrapper\",\n",
    "        \"scenario\",\n",
    "        \"DelayNoiseWrapperOption2\",\n",
    "        \"DelayNoiseWrapperOption1\",\n",
    "        \"combination\",\n",
    "        \"ObservationVariesNoiseWrapper1\",\n",
    "        \"ObservationVariesPositiveNoiseWrapper\",\n",
    "        \"ObservationVariesNegativeNoiseWrapper\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "order_of_col = [\n",
    "    \"ObservationVariesPositiveNoiseWrapper\",\n",
    "    \"ObservationVariesNegativeNoiseWrapper\",\n",
    "    \"ObservationVariesNoiseWrapper1\",\n",
    "    \"DelayNoiseWrapperOption1\",\n",
    "    \"DelayNoiseWrapperOption2\",\n",
    "]\n",
    "fig, ax = plt.subplots(constrained_layout=True)\n",
    "fig.set_figwidth(14)\n",
    "\n",
    "ax1 = ax.boxplot(\n",
    "    noise_df.query(\n",
    "        \"combination=='src/main/rl/models/scenario1/training_04_06/scenario1_ActionSpaceOption3Wrapper_ObservationOption5Wrapper_None_RewardOption2Wrapper_SAC_training_04_06'\"\n",
    "    )[order_of_col],\n",
    "    positions=[0, 0.2, 0.4, 0.6, 0.8],\n",
    "    labels=[\"1a\", \"1b\", \"1c\", \"2a\", \"2b\"],\n",
    ")\n",
    "ax2 = ax.boxplot(\n",
    "    noise_df.query(\n",
    "        \"combination=='src/main/rl/models/scenario1/training_04_06/scenario1_ActionSpaceOption3Wrapper_ObservationOption5Wrapper_NPPAutomationWrapper_RewardOption2Wrapper_SAC_training_04_06'\"\n",
    "    )[order_of_col],\n",
    "    positions=[1.2, 1.4, 1.6, 1.8, 2],\n",
    "    labels=[\"1a\", \"1b\", \"1c\", \"2a\", \"2b\"],\n",
    ")\n",
    "ax3 = ax.boxplot(\n",
    "    noise_df.query(\n",
    "        \"combination=='src/main/rl/models/scenario2/training_04_06/scenario2_ActionSpaceOption3Wrapper_ObservationOption5Wrapper_None_RewardOption2Wrapper_PPO_training_04_06'\"\n",
    "    )[order_of_col],\n",
    "    positions=[2.4, 2.6, 2.8, 3, 3.2],\n",
    "    labels=[\"1a\", \"1b\", \"1c\", \"2a\", \"2b\"],\n",
    ")\n",
    "ax4 = ax.boxplot(\n",
    "    noise_df.query(\n",
    "        \"combination=='src/main/rl/models/scenario2/training_04_06/scenario2_ActionSpaceOption3Wrapper_ObservationOption4Wrapper_NPPAutomationWrapper_RewardOption2Wrapper_PPO_training_04_06'\"\n",
    "    )[order_of_col],\n",
    "    positions=[3.6, 3.8, 4, 4.2, 4.4],\n",
    "    labels=[\"1a\", \"1b\", \"1c\", \"2a\", \"2b\"],\n",
    ")\n",
    "ax5 = ax.boxplot(\n",
    "    noise_df.query(\n",
    "        \"combination=='src/main/rl/models/scenario3/training_04_06/scenario3_ActionSpaceOption3Wrapper_ObservationOption5Wrapper_None_RewardOption2Wrapper_PPO_training_04_06'\"\n",
    "    )[order_of_col],\n",
    "    positions=[4.8, 5, 5.2, 5.4, 5.6],\n",
    "    labels=[\"1a\", \"1b\", \"1c\", \"2a\", \"2b\"],\n",
    ")\n",
    "ax6 = ax.boxplot(\n",
    "    noise_df.query(\n",
    "        \"combination=='src/main/rl/models/scenario3/training_04_06/scenario3_ActionSpaceOption3Wrapper_ObservationOption3Wrapper_NPPAutomationWrapper_RewardOption2Wrapper_PPO_training_04_06'\"\n",
    "    )[order_of_col],\n",
    "    positions=[6, 6.2, 6.4, 6.6, 6.8],\n",
    "    labels=[\"1a\", \"1b\", \"1c\", \"2a\", \"2b\"],\n",
    ")\n",
    "set_box_color(ax1, color_mapping[\"blue\"], 0)\n",
    "set_box_color(ax1, color_mapping[\"blue\"], 1)\n",
    "set_box_color(ax2, color_mapping[\"red\"], 0)\n",
    "set_box_color(ax2, color_mapping[\"red\"], 1)\n",
    "set_box_color(ax3, color_mapping[\"grey\"], 0)\n",
    "set_box_color(ax3, color_mapping[\"grey\"], 1)\n",
    "set_box_color(ax4, color_mapping[\"yellow\"], 0)\n",
    "set_box_color(ax4, color_mapping[\"yellow\"], 1)\n",
    "set_box_color(ax5, color_mapping[\"brown\"], 0)\n",
    "set_box_color(ax5, color_mapping[\"brown\"], 1)\n",
    "set_box_color(ax6, color_mapping[\"turquoise\"], 0)\n",
    "set_box_color(ax6, color_mapping[\"turquoise\"], 1)\n",
    "ax.set_xlabel(\"Rauschoptionen\")\n",
    "ax.set_ylabel(\"Absolvierte Zeitschritte\")\n",
    "plt.plot([], c=color_mapping[\"blue\"], label=\"Kombination 1\")\n",
    "plt.plot([], c=color_mapping[\"red\"], label=\"Kombination 2\")\n",
    "plt.plot([], c=color_mapping[\"grey\"], label=\"Kombination 3\")\n",
    "plt.plot([], c=color_mapping[\"yellow\"], label=\"Kombination 4\")\n",
    "plt.plot([], c=color_mapping[\"brown\"], label=\"Kombination 5\")\n",
    "plt.plot([], c=color_mapping[\"turquoise\"], label=\"Kombination 6\")\n",
    "plt.legend(loc=[0.2, 0.1])\n",
    "\n",
    "plt.show()\n",
    "plt.tight_layout = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Successfull number of model-noise combinations per combination (max 50 -> 5 noise options * 10 models)\n",
    "# Successfull meaning here to have completed the 250 timesteps fully\n",
    "noise_agg = (\n",
    "    df[\n",
    "        [\n",
    "            \"DelayNoiseWrapperOption2_timesteps\",\n",
    "            \"DelayNoiseWrapperOption1_timesteps\",\n",
    "            \"ObservationVariesNoiseWrapper1_timesteps\",\n",
    "            \"ObservationVariesNoiseWrapper1_timesteps\",\n",
    "            \"ObservationVariesNegativeNoiseWrapper_timesteps\",\n",
    "            \"combination\",\n",
    "        ]\n",
    "    ]\n",
    "    .set_index(\"combination\")\n",
    "    .eq(250)\n",
    "    .groupby(\"combination\")\n",
    "    .sum()\n",
    "    .transpose()\n",
    "    .sum()\n",
    "    .transpose()\n",
    "    .to_latex()\n",
    ")\n",
    "print(noise_agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting State\n",
    "cols = [col for col in df.columns if \"starting\" in col and \"criticality\" not in col]\n",
    "# Mean auf all strating state options (return + timesteps)\n",
    "df[cols].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting state 1 - Models that were not executing the 250 timesteps completly\n",
    "df[df[\"create_starting_state_option1_timesteps\"] != 250]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box Plots for starting state 2 per option and per combination using timesteps\n",
    "def set_box_color(bp, color, idx):\n",
    "    plt.setp(bp[\"boxes\"], color=color)\n",
    "    plt.setp(bp[\"whiskers\"], color=color)\n",
    "    plt.setp(bp[\"caps\"], color=color)\n",
    "    plt.setp(bp[\"medians\"], color=color)\n",
    "    plt.setp(bp[\"caps\"], color=color)\n",
    "    plt.setp(bp[\"fliers\"], color=color)\n",
    "\n",
    "\n",
    "starting_state2 = df[\n",
    "    [\n",
    "        \"combination\",\n",
    "        \"create_starting_state_option2a_timesteps\",\n",
    "        \"create_starting_state_option2b_timesteps\",\n",
    "        \"create_starting_state_option2c_timesteps\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "order_of_col = [\n",
    "    \"create_starting_state_option2a_timesteps\",\n",
    "    \"create_starting_state_option2b_timesteps\",\n",
    "    \"create_starting_state_option2c_timesteps\",\n",
    "]\n",
    "fig, ax = plt.subplots(constrained_layout=True)\n",
    "fig.set_figwidth(8)\n",
    "ax1 = ax.boxplot(\n",
    "    starting_state2.query(\n",
    "        \"combination=='src/main/rl/models/scenario1/training_04_06/scenario1_ActionSpaceOption3Wrapper_ObservationOption5Wrapper_None_RewardOption2Wrapper_SAC_training_04_06'\"\n",
    "    )[order_of_col],\n",
    "    positions=[\n",
    "        0,\n",
    "        0.2,\n",
    "        0.4,\n",
    "    ],\n",
    "    labels=[\n",
    "        \"2a\",\n",
    "        \"2b\",\n",
    "        \"2c\",\n",
    "    ],\n",
    ")\n",
    "ax2 = ax.boxplot(\n",
    "    starting_state2.query(\n",
    "        \"combination=='src/main/rl/models/scenario1/training_04_06/scenario1_ActionSpaceOption3Wrapper_ObservationOption5Wrapper_NPPAutomationWrapper_RewardOption2Wrapper_SAC_training_04_06'\"\n",
    "    )[order_of_col],\n",
    "    positions=[\n",
    "        0.9,\n",
    "        1.1,\n",
    "        1.3,\n",
    "    ],\n",
    "    labels=[\n",
    "        \"2a\",\n",
    "        \"2b\",\n",
    "        \"2c\",\n",
    "    ],\n",
    ")\n",
    "ax3 = ax.boxplot(\n",
    "    starting_state2.query(\n",
    "        \"combination=='src/main/rl/models/scenario2/training_04_06/scenario2_ActionSpaceOption3Wrapper_ObservationOption5Wrapper_None_RewardOption2Wrapper_PPO_training_04_06'\"\n",
    "    )[order_of_col],\n",
    "    positions=[1.8, 2, 2.2],\n",
    "    labels=[\n",
    "        \"2a\",\n",
    "        \"2b\",\n",
    "        \"2c\",\n",
    "    ],\n",
    ")\n",
    "ax4 = ax.boxplot(\n",
    "    starting_state2.query(\n",
    "        \"combination=='src/main/rl/models/scenario2/training_04_06/scenario2_ActionSpaceOption3Wrapper_ObservationOption4Wrapper_NPPAutomationWrapper_RewardOption2Wrapper_PPO_training_04_06'\"\n",
    "    )[order_of_col],\n",
    "    positions=[2.7, 2.9, 3.1],\n",
    "    labels=[\n",
    "        \"2a\",\n",
    "        \"2b\",\n",
    "        \"2c\",\n",
    "    ],\n",
    ")\n",
    "ax5 = ax.boxplot(\n",
    "    starting_state2.query(\n",
    "        \"combination=='src/main/rl/models/scenario3/training_04_06/scenario3_ActionSpaceOption3Wrapper_ObservationOption5Wrapper_None_RewardOption2Wrapper_PPO_training_04_06'\"\n",
    "    )[order_of_col],\n",
    "    positions=[3.6, 3.8, 4],\n",
    "    labels=[\n",
    "        \"2a\",\n",
    "        \"2b\",\n",
    "        \"2c\",\n",
    "    ],\n",
    ")\n",
    "ax6 = ax.boxplot(\n",
    "    starting_state2.query(\n",
    "        \"combination=='src/main/rl/models/scenario3/training_04_06/scenario3_ActionSpaceOption3Wrapper_ObservationOption3Wrapper_NPPAutomationWrapper_RewardOption2Wrapper_PPO_training_04_06'\"\n",
    "    )[order_of_col],\n",
    "    positions=[4.5, 4.7, 4.9],\n",
    "    labels=[\n",
    "        \"2a\",\n",
    "        \"2b\",\n",
    "        \"2c\",\n",
    "    ],\n",
    ")\n",
    "set_box_color(ax1, color_mapping[\"blue\"], 0)\n",
    "set_box_color(ax1, color_mapping[\"blue\"], 1)\n",
    "set_box_color(ax2, color_mapping[\"red\"], 0)\n",
    "set_box_color(ax2, color_mapping[\"red\"], 1)\n",
    "set_box_color(ax3, color_mapping[\"grey\"], 0)\n",
    "set_box_color(ax3, color_mapping[\"grey\"], 1)\n",
    "set_box_color(ax4, color_mapping[\"yellow\"], 0)\n",
    "set_box_color(ax4, color_mapping[\"yellow\"], 1)\n",
    "set_box_color(ax5, color_mapping[\"brown\"], 0)\n",
    "set_box_color(ax5, color_mapping[\"brown\"], 1)\n",
    "set_box_color(ax6, color_mapping[\"turquoise\"], 0)\n",
    "set_box_color(ax6, color_mapping[\"turquoise\"], 1)\n",
    "ax.set_xlabel(\"Startzustände\")\n",
    "ax.set_ylabel(\"Absolvierte Zeitschritte\")\n",
    "plt.plot([], c=color_mapping[\"blue\"], label=\"Kombination 1\")\n",
    "plt.plot([], c=color_mapping[\"red\"], label=\"Kombination 2\")\n",
    "plt.plot([], c=color_mapping[\"grey\"], label=\"Kombination 3\")\n",
    "plt.plot([], c=color_mapping[\"yellow\"], label=\"Kombination 4\")\n",
    "plt.plot([], c=color_mapping[\"brown\"], label=\"Kombination 5\")\n",
    "plt.plot([], c=color_mapping[\"turquoise\"], label=\"Kombination 6\")\n",
    "plt.legend(loc=[0.35, 0.5])\n",
    "plt.show()\n",
    "fig.savefig(\n",
    "    f\"src/main/rl/evaluation/plot_results/phase3_starting_state_2_by_combi.png\",\n",
    "    format=\"png\",\n",
    "    dpi=300,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many models have successfully completed the 250 timesteps per starting state option\n",
    "starting_state2.eq(250).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box Plots for starting state 2 per option and per combination using return\n",
    "def set_box_color(bp, color, idx):\n",
    "    plt.setp(bp[\"boxes\"], color=color)\n",
    "    plt.setp(bp[\"whiskers\"], color=color)\n",
    "    plt.setp(bp[\"caps\"], color=color)\n",
    "    plt.setp(bp[\"medians\"], color=color)\n",
    "    plt.setp(bp[\"caps\"], color=color)\n",
    "    plt.setp(bp[\"fliers\"], color=color)\n",
    "\n",
    "\n",
    "starting_state2 = df[\n",
    "    [\n",
    "        \"combination\",\n",
    "        \"create_starting_state_option2a\",\n",
    "        \"create_starting_state_option2b\",\n",
    "        \"create_starting_state_option2c\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "order_of_col = [\n",
    "    \"create_starting_state_option2a\",\n",
    "    \"create_starting_state_option2b\",\n",
    "    \"create_starting_state_option2c\",\n",
    "]\n",
    "fig, ax = plt.subplots(constrained_layout=True)\n",
    "fig.set_figwidth(8)\n",
    "ax1 = ax.boxplot(\n",
    "    starting_state2.query(\n",
    "        \"combination=='src/main/rl/models/scenario1/training_04_06/scenario1_ActionSpaceOption3Wrapper_ObservationOption5Wrapper_None_RewardOption2Wrapper_SAC_training_04_06'\"\n",
    "    )[order_of_col],\n",
    "    positions=[\n",
    "        0,\n",
    "        0.2,\n",
    "        0.4,\n",
    "    ],\n",
    "    labels=[\n",
    "        \"2a\",\n",
    "        \"2b\",\n",
    "        \"2c\",\n",
    "    ],\n",
    ")\n",
    "ax2 = ax.boxplot(\n",
    "    starting_state2.query(\n",
    "        \"combination=='src/main/rl/models/scenario1/training_04_06/scenario1_ActionSpaceOption3Wrapper_ObservationOption5Wrapper_NPPAutomationWrapper_RewardOption2Wrapper_SAC_training_04_06'\"\n",
    "    )[order_of_col],\n",
    "    positions=[\n",
    "        0.9,\n",
    "        1.1,\n",
    "        1.3,\n",
    "    ],\n",
    "    labels=[\n",
    "        \"2a\",\n",
    "        \"2b\",\n",
    "        \"2c\",\n",
    "    ],\n",
    ")\n",
    "ax3 = ax.boxplot(\n",
    "    starting_state2.query(\n",
    "        \"combination=='src/main/rl/models/scenario2/training_04_06/scenario2_ActionSpaceOption3Wrapper_ObservationOption5Wrapper_None_RewardOption2Wrapper_PPO_training_04_06'\"\n",
    "    )[order_of_col],\n",
    "    positions=[1.8, 2, 2.2],\n",
    "    labels=[\n",
    "        \"2a\",\n",
    "        \"2b\",\n",
    "        \"2c\",\n",
    "    ],\n",
    ")\n",
    "ax4 = ax.boxplot(\n",
    "    starting_state2.query(\n",
    "        \"combination=='src/main/rl/models/scenario2/training_04_06/scenario2_ActionSpaceOption3Wrapper_ObservationOption4Wrapper_NPPAutomationWrapper_RewardOption2Wrapper_PPO_training_04_06'\"\n",
    "    )[order_of_col],\n",
    "    positions=[2.7, 2.9, 3.1],\n",
    "    labels=[\n",
    "        \"2a\",\n",
    "        \"2b\",\n",
    "        \"2c\",\n",
    "    ],\n",
    ")\n",
    "ax5 = ax.boxplot(\n",
    "    starting_state2.query(\n",
    "        \"combination=='src/main/rl/models/scenario3/training_04_06/scenario3_ActionSpaceOption3Wrapper_ObservationOption5Wrapper_None_RewardOption2Wrapper_PPO_training_04_06'\"\n",
    "    )[order_of_col],\n",
    "    positions=[3.6, 3.8, 4],\n",
    "    labels=[\n",
    "        \"2a\",\n",
    "        \"2b\",\n",
    "        \"2c\",\n",
    "    ],\n",
    ")\n",
    "ax6 = ax.boxplot(\n",
    "    starting_state2.query(\n",
    "        \"combination=='src/main/rl/models/scenario3/training_04_06/scenario3_ActionSpaceOption3Wrapper_ObservationOption3Wrapper_NPPAutomationWrapper_RewardOption2Wrapper_PPO_training_04_06'\"\n",
    "    )[order_of_col],\n",
    "    positions=[4.5, 4.7, 4.9],\n",
    "    labels=[\n",
    "        \"2a\",\n",
    "        \"2b\",\n",
    "        \"2c\",\n",
    "    ],\n",
    ")\n",
    "set_box_color(ax1, color_mapping[\"blue\"], 0)\n",
    "set_box_color(ax1, color_mapping[\"blue\"], 1)\n",
    "set_box_color(ax2, color_mapping[\"red\"], 0)\n",
    "set_box_color(ax2, color_mapping[\"red\"], 1)\n",
    "set_box_color(ax3, color_mapping[\"grey\"], 0)\n",
    "set_box_color(ax3, color_mapping[\"grey\"], 1)\n",
    "set_box_color(ax4, color_mapping[\"yellow\"], 0)\n",
    "set_box_color(ax4, color_mapping[\"yellow\"], 1)\n",
    "set_box_color(ax5, color_mapping[\"brown\"], 0)\n",
    "set_box_color(ax5, color_mapping[\"brown\"], 1)\n",
    "set_box_color(ax6, color_mapping[\"turquoise\"], 0)\n",
    "set_box_color(ax6, color_mapping[\"turquoise\"], 1)\n",
    "ax.set_xlabel(\"Startzustände\")\n",
    "ax.set_ylabel(\"Absolvierte Zeitschritte\")\n",
    "plt.plot([], c=color_mapping[\"blue\"], label=\"Kombination 1\")\n",
    "plt.plot([], c=color_mapping[\"red\"], label=\"Kombination 2\")\n",
    "plt.plot([], c=color_mapping[\"grey\"], label=\"Kombination 3\")\n",
    "plt.plot([], c=color_mapping[\"yellow\"], label=\"Kombination 4\")\n",
    "plt.plot([], c=color_mapping[\"brown\"], label=\"Kombination 5\")\n",
    "plt.plot([], c=color_mapping[\"turquoise\"], label=\"Kombination 6\")\n",
    "plt.legend(loc=[0.35, 0.5])\n",
    "plt.show()\n",
    "fig.savefig(\n",
    "    f\"src/main/rl/evaluation/plot_results/phase3_starting_state_2_by_combi.png\",\n",
    "    format=\"png\",\n",
    "    dpi=300,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting state 3 per combination mean timesteps completed\n",
    "starting_state3 = df[\n",
    "    [\n",
    "        \"obs_wrapper\",\n",
    "        \"combination\",\n",
    "        \"automation_wrapper\",\n",
    "        \"scenario\",\n",
    "        \"create_starting_state_option3_timesteps\",\n",
    "    ]\n",
    "]\n",
    "starting_state3.groupby(\"combination\").agg(\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting state 3 completed 250 timesteps (number of models out of 60)\n",
    "starting_state3.eq(250).sum(axis=1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting state options per combination timestep statistics\n",
    "df_statistics_per_combination[\n",
    "    [\n",
    "        \"create_starting_state_option1_timesteps_mean\",\n",
    "        \"create_starting_state_option2a_timesteps_mean\",\n",
    "        \"create_starting_state_option2b_timesteps_mean\",\n",
    "        \"create_starting_state_option2c_timesteps_mean\",\n",
    "        \"create_starting_state_option3_timesteps_mean\",\n",
    "    ]\n",
    "].agg([\"mean\", \"max\", \"min\", \"std\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting state options per model return statistics\n",
    "df[\n",
    "    [\n",
    "        \"create_starting_state_option1\",\n",
    "        \"create_starting_state_option2a\",\n",
    "        \"create_starting_state_option2b\",\n",
    "        \"create_starting_state_option2c\",\n",
    "        \"create_starting_state_option3\",\n",
    "    ]\n",
    "].agg([\"mean\", \"max\", \"min\", \"std\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting state options per combination timestep statistics\n",
    "print(\n",
    "    df_statistics_per_combination[\n",
    "        [\n",
    "            \"create_starting_state_option1_timesteps_mean\",\n",
    "            \"create_starting_state_option2a_timesteps_mean\",\n",
    "            \"create_starting_state_option2b_timesteps_mean\",\n",
    "            \"create_starting_state_option2c_timesteps_mean\",\n",
    "            \"create_starting_state_option3_timesteps_mean\",\n",
    "        ]\n",
    "    ]\n",
    "    .agg([\"mean\", \"max\", \"min\", \"std\"], axis=1)\n",
    "    .droplevel(1)\n",
    "    .round(2)\n",
    "    .transpose()\n",
    "    .to_latex()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Successfull number of model-starting-state combinations per combination (max 50 -> 5 noise options * 10 models)\n",
    "# Successfull meaning here to have completed the 250 timesteps fully\n",
    "starting_state_2 = (\n",
    "    df[\n",
    "        [\n",
    "            \"create_starting_state_option1_timesteps\",\n",
    "            \"create_starting_state_option2a_timesteps\",\n",
    "            \"create_starting_state_option2b_timesteps\",\n",
    "            \"create_starting_state_option2c_timesteps\",\n",
    "            \"create_starting_state_option3_timesteps\",\n",
    "            \"combination\",\n",
    "        ]\n",
    "    ]\n",
    "    .set_index(\"combination\")\n",
    "    .eq(250)\n",
    "    .groupby(\"combination\")\n",
    "    .sum()\n",
    "    .transpose()\n",
    "    .sum()\n",
    "    .transpose()\n",
    "    .to_latex()\n",
    ")\n",
    "\n",
    "print(starting_state_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of model-experiment combinations that sucessfully executed all timesteps during the specific experiment.\n",
    "# In total there were 660 such combinations\n",
    "(\n",
    "    df[\n",
    "        [\n",
    "            \"DelayNoiseWrapperOption2_timesteps\",\n",
    "            \"DelayNoiseWrapperOption1_timesteps\",\n",
    "            \"ObservationVariesNoiseWrapper1_timesteps\",\n",
    "            \"ObservationVariesNoiseWrapper1_timesteps\",\n",
    "            \"ObservationVariesNegativeNoiseWrapper_timesteps\",\n",
    "            \"create_starting_state_option1_timesteps\",\n",
    "            \"create_starting_state_option2a_timesteps\",\n",
    "            \"create_starting_state_option2b_timesteps\",\n",
    "            \"create_starting_state_option2c_timesteps\",\n",
    "            \"create_starting_state_option3_timesteps\",\n",
    "        ]\n",
    "    ]\n",
    "    .eq(250)\n",
    "    .sum()\n",
    "    .sum()\n",
    "    + df[\"episode_length_1000_timesteps\"].eq(1000).sum()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of model-experiment combinations per combination that sucessfully executed all timesteps during the specific experiment.\n",
    "# In total there were 110 such combinations per combination\n",
    "# Carefull: The order of the combination might not be the same as in the thesis!\n",
    "\n",
    "\n",
    "def get_counts_by_group(df, max_timesteps):\n",
    "    return df.eq(max_timesteps).sum()\n",
    "\n",
    "\n",
    "counts_noise = (\n",
    "    df[\n",
    "        [\n",
    "            \"combination\",\n",
    "            \"DelayNoiseWrapperOption2_timesteps\",\n",
    "            \"DelayNoiseWrapperOption1_timesteps\",\n",
    "            \"ObservationVariesNoiseWrapper1_timesteps\",\n",
    "            \"ObservationVariesNoiseWrapper1_timesteps\",\n",
    "            \"ObservationVariesNegativeNoiseWrapper_timesteps\",\n",
    "        ]\n",
    "    ]\n",
    "    .groupby(\"combination\")\n",
    "    .apply(get_counts_by_group, (250))\n",
    ").sum(axis=1)\n",
    "counts_starting_state = (\n",
    "    df[\n",
    "        [\n",
    "            \"combination\",\n",
    "            \"create_starting_state_option1_timesteps\",\n",
    "            \"create_starting_state_option2a_timesteps\",\n",
    "            \"create_starting_state_option2b_timesteps\",\n",
    "            \"create_starting_state_option2c_timesteps\",\n",
    "            \"create_starting_state_option3_timesteps\",\n",
    "        ]\n",
    "    ]\n",
    "    .groupby(\"combination\")\n",
    "    .apply(get_counts_by_group, (250))\n",
    ").sum(axis=1)\n",
    "counts_1000 = (\n",
    "    df[[\"combination\", \"episode_length_1000_timesteps\"]]\n",
    "    .groupby(\"combination\")\n",
    "    .apply(get_counts_by_group, (1000))[\"episode_length_1000_timesteps\"]\n",
    ")\n",
    "\n",
    "print(\"Counts over all modification experiments with noise:\")\n",
    "print(counts_noise)\n",
    "print(\"Counts over all modification experiments with starting states:\")\n",
    "print(counts_starting_state)\n",
    "print(\"Counts over all modification experiment with 100 length:\")\n",
    "print(counts_1000)\n",
    "\n",
    "print(\"Counts over all modification experiments:\")\n",
    "print(counts_noise + counts_starting_state + counts_1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
