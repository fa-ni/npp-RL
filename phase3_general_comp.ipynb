{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8acfb16-0d15-41ab-928d-99e31db77858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preperation for obs and action plotting\n",
    "import pandas as pd\n",
    "from src.main.rl.evaluation.plots.phase3_plots import prepare_one_combination_actions_and_obs_for_analysis\n",
    "from src.main.rl.utils.constants import color_mapping\n",
    "from src.main.rl.utils.constants import (\n",
    "    scaling_factors_scenario_1,\n",
    "    scaling_factors_scenario_2,\n",
    "    scaling_factors_scenario_3,\n",
    "    action_dimensions_german,\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "paths = [\n",
    "    \"src/main/rl/models/scenario1/training_04_06/scenario1_ActionSpaceOption3Wrapper_ObservationOption4Wrapper_None_RewardOption2Wrapper_TD3_training_04_06\",\n",
    "    \"src/main/rl/models/scenario1/training_04_06/scenario1_ActionSpaceOption3Wrapper_ObservationOption5Wrapper_NPPAutomationWrapper_RewardOption2Wrapper_SAC_training_04_06\",\n",
    "    \"src/main/rl/models/scenario2/training_04_06/scenario2_ActionSpaceOption3Wrapper_ObservationOption5Wrapper_None_RewardOption2Wrapper_PPO_training_04_06\",\n",
    "    \"src/main/rl/models/scenario2/training_04_06/scenario2_ActionSpaceOption3Wrapper_ObservationOption4Wrapper_NPPAutomationWrapper_RewardOption2Wrapper_PPO_training_04_06\",\n",
    "    \"src/main/rl/models/scenario3/training_04_06/scenario3_ActionSpaceOption3Wrapper_ObservationOption5Wrapper_None_RewardOption2Wrapper_PPO_training_04_06\",\n",
    "    \"src/main/rl/models/scenario3/training_04_06/scenario3_ActionSpaceOption3Wrapper_ObservationOption3Wrapper_NPPAutomationWrapper_RewardOption2Wrapper_PPO_training_04_06\",\n",
    "]\n",
    "list_actions_prepared = []\n",
    "list_obs_prepared = []\n",
    "list_list_of_all_actions_taken = []\n",
    "list_list_of_all_obs_taken = []\n",
    "obs_dimensions = [6, 11, 11, 6, 11, 7]\n",
    "scaling_functions = [\n",
    "    lambda x: int(round((x + 1) * (scaling_factors[list_idx][idx] / 2))),\n",
    "    lambda x: int(round((x + 1) * (scaling_factors[list_idx][idx] / 2))),\n",
    "    lambda x: -scaling_factors_scenario_2[idx] if x == 0 else scaling_factors_scenario_2[idx],\n",
    "    lambda x: -scaling_factors_scenario_2[idx] if x == 0 else scaling_factors_scenario_2[idx],\n",
    "    lambda x: scaling_factors_scenario_3[idx][x],\n",
    "    lambda x: scaling_factors_scenario_3[idx][x],\n",
    "]\n",
    "scaling_factors = [\n",
    "    scaling_factors_scenario_1,\n",
    "    scaling_factors_scenario_1,\n",
    "    scaling_factors_scenario_2,\n",
    "    scaling_factors_scenario_2,\n",
    "    scaling_factors_scenario_3,\n",
    "    scaling_factors_scenario_3,\n",
    "]\n",
    "for idx, path in enumerate(paths):\n",
    "    (\n",
    "        actions_prepared,\n",
    "        obs_prepared,\n",
    "        list_of_all_actions_taken,\n",
    "        list_of_all_obs_taken,\n",
    "    ) = prepare_one_combination_actions_and_obs_for_analysis(path, obs_dimensions=obs_dimensions[idx])\n",
    "    list_actions_prepared.append(actions_prepared)\n",
    "    list_obs_prepared.append(obs_prepared)\n",
    "    list_list_of_all_actions_taken.append(list_of_all_actions_taken)\n",
    "    list_list_of_all_obs_taken.append(list_of_all_obs_taken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1de9ae-1f13-4eee-b441-6dc87cb6bea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Create all actions taken mean (min, max) for all 6 combis #######\n",
    "for list_idx, actions_prepared in enumerate(list_actions_prepared):\n",
    "    for idx, item in enumerate(actions_prepared):\n",
    "        item = item.applymap(scaling_functions[list_idx])\n",
    "        actions_prepared[idx] = item.agg([\"mean\", \"min\", \"max\", \"std\"], axis=1)\n",
    "        actions_prepared[idx][\"minus\"] = actions_prepared[idx][\"mean\"] - actions_prepared[idx][\"std\"]\n",
    "        actions_prepared[idx][\"plus\"] = actions_prepared[idx][\"mean\"] + actions_prepared[idx][\"std\"]\n",
    "    fig, ax = plt.subplots(1, 5, constrained_layout=True)\n",
    "    fig.set_figheight(3)\n",
    "    fig.set_figwidth(20)\n",
    "    [ax[idx].plot(item[\"mean\"], color=color_mapping[\"standard\"]) for idx, item in enumerate(actions_prepared)]\n",
    "    [\n",
    "        ax[idx].fill_between(\n",
    "            [i for i in range(251)], item[\"min\"], item[\"max\"], color=color_mapping[\"standard\"], alpha=0.3\n",
    "        )\n",
    "        for idx, item in enumerate(actions_prepared)\n",
    "    ]\n",
    "    [ax[idx].set_xlabel(\"Zeitschritte\") for idx in range(5)]\n",
    "    [ax[idx].set_ylabel(\"Value\") for idx in range(5)]\n",
    "    [ax[idx].set_title(action_dimensions_german[idx]) for idx in range(5)]\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce84d912-ec20-455e-bd3f-89565ad95d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Create all obs taken mean (min, max) for all 6 combis #######\n",
    "from src.main.rl.utils.constants import (\n",
    "    scaling_factors_scenario_1,\n",
    "    scaling_factors_scenario_2,\n",
    "    action_dimensions_german,\n",
    "    obs_dimensions_german,\n",
    "    obs_scaling_factors,\n",
    "    obs_dimensions,\n",
    "    scaling_factors_scenario_3,\n",
    ")\n",
    "\n",
    "obs_dimensions = [6, 11, 11, 6, 11, 7]\n",
    "\n",
    "for list_idx, obs_prepared in enumerate(list_obs_prepared):\n",
    "    obs_space_size = obs_dimensions[list_idx]\n",
    "    current_obs_scaling_factors = obs_scaling_factors[obs_space_size]\n",
    "    agg_result_list_obs = [pd.DataFrame() for _ in range(obs_space_size)]\n",
    "    # y_axis_scale=[[0,1000],[0,4000],[0,550],[0,8000],[0,180],[0,32]]\n",
    "    fig, ax = plt.subplots(1, int(obs_space_size), constrained_layout=True)\n",
    "    fig.set_figheight(3)\n",
    "    fig.set_figwidth(30)\n",
    "    for idx, item in enumerate(obs_prepared):\n",
    "        item = item.fillna(0)\n",
    "        item = item.applymap(lambda x: int(round((x + 1) * (current_obs_scaling_factors[idx] / 2))))\n",
    "        agg_result_list_obs[idx] = item.agg([\"mean\", \"min\", \"max\", \"std\"], axis=1)\n",
    "        agg_result_list_obs[idx][\"minus\"] = agg_result_list_obs[idx][\"mean\"] - agg_result_list_obs[idx][\"std\"]\n",
    "        agg_result_list_obs[idx][\"plus\"] = agg_result_list_obs[idx][\"mean\"] + agg_result_list_obs[idx][\"std\"]\n",
    "        # [ax[idx].plot(item[column],color=color_mapping[\"standard\"]) for idx, item in enumerate(no_agg_result_list_obs)]\n",
    "\n",
    "    [ax[idx].plot(item[\"mean\"], color=color_mapping[\"standard\"]) for idx, item in enumerate(agg_result_list_obs)]\n",
    "    [\n",
    "        ax[idx].fill_between(\n",
    "            [i for i in range(251)], item[\"min\"], item[\"max\"], color=color_mapping[\"standard\"], alpha=0.3\n",
    "        )\n",
    "        for idx, item in enumerate(agg_result_list_obs)\n",
    "    ]\n",
    "    [ax[idx].set_xlabel(\"Zeitschritte\") for idx in range(obs_space_size)]\n",
    "    [ax[idx].set_ylabel(\"Value\") for idx in range(obs_space_size)]\n",
    "    [ax[idx].set_title(obs_dimensions_german[obs_space_size][idx]) for idx in range(obs_space_size)]\n",
    "    # [ax[idx].axhline(red_critical_line_1[idx],color=color_mapping[\"red\"],ls='--') for idx in range(obs_space_size)]\n",
    "    # [ax[idx].axhline(red_critical_line_2[idx],color=color_mapping[\"red\"],ls='--') for idx in range(obs_space_size)]\n",
    "    # [ax[idx].axhline(orange_critical_line_1[idx],color=color_mapping[\"orange\"],ls='--') for idx in range(obs_space_size)]\n",
    "    # [ax[idx].axhline(orange_critical_line_2[idx],color=color_mapping[\"orange\"],ls='--') for idx in range(obs_space_size)]\n",
    "    # [ax[idx].axhline(dead_line_1[idx],color=\"black\",ls='--') for idx in range(obs_space_size)]\n",
    "    # [ax[idx].axhline(dead_line_2[idx],color=\"black\",ls='--') for idx in range(obs_space_size)]\n",
    "    # [ax[idx].set_ylim(y_axis_scale[idx]) for idx in range(obs_space_size)]\n",
    "\n",
    "    # fig.savefig(\n",
    "#    f\"src/main/rl/evaluation/plot_results/phase3_obs_plot_with_min_max_scen1_wo_all_models.png\",\n",
    "#    format=\"png\",\n",
    "#    dpi=300,\n",
    "# )\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98484501-a9f1-42b5-8e1d-0a97faf5c9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Stripe Plot\n",
    "import seaborn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "paths = [\n",
    "    \"src/main/rl/models/scenario1/training_04_06/scenario1_ActionSpaceOption3Wrapper_ObservationOption4Wrapper_None_RewardOption2Wrapper_TD3_training_04_06\",\n",
    "    \"src/main/rl/models/scenario1/training_04_06/scenario1_ActionSpaceOption3Wrapper_ObservationOption5Wrapper_NPPAutomationWrapper_RewardOption2Wrapper_SAC_training_04_06\",\n",
    "    \"src/main/rl/models/scenario2/training_04_06/scenario2_ActionSpaceOption3Wrapper_ObservationOption5Wrapper_None_RewardOption2Wrapper_PPO_training_04_06\",\n",
    "    \"src/main/rl/models/scenario2/training_04_06/scenario2_ActionSpaceOption3Wrapper_ObservationOption4Wrapper_NPPAutomationWrapper_RewardOption2Wrapper_PPO_training_04_06\",\n",
    "    \"src/main/rl/models/scenario3/training_04_06/scenario3_ActionSpaceOption3Wrapper_ObservationOption5Wrapper_None_RewardOption2Wrapper_PPO_training_04_06\",\n",
    "    \"src/main/rl/models/scenario3/training_04_06/scenario3_ActionSpaceOption3Wrapper_ObservationOption5Wrapper_NPPAutomationWrapper_RewardOption2Wrapper_A2C_training_04_06\",\n",
    "]\n",
    "path_to_save = \"src/main/rl/evaluation/output/phase3_evaluation_results_new3.csv\"\n",
    "pd.options.display.max_colwidth = 500\n",
    "df = pd.DataFrame()\n",
    "try:\n",
    "    df = pd.read_csv(path_to_save)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "if df.empty:\n",
    "    df = create_evaluation_df_phase3(path_to_save, paths)\n",
    "df\n",
    "seaborn.set(style=\"white\")\n",
    "# loading data-set\n",
    "# TODO add ticks\n",
    "ax = seaborn.stripplot(\n",
    "    x=df[\"combination\"],\n",
    "    y=df[\"cum_reward\"],\n",
    "    jitter=0.1,\n",
    "    color=color_mapping[\"standard\"],\n",
    "    dodge=True,\n",
    "    size=6,\n",
    ")\n",
    "ax.set(xticklabels=[\"1\", \"2\", \"3\", \"4\", \"5\", \"6\"])\n",
    "ax.set_xlabel(\"Kombination\")\n",
    "ax.set_ylabel(\"Return\")\n",
    "ax.margins(x=0.1)\n",
    "ax.set(yticks=[160, 180, 200, 220, 240])\n",
    "fig = ax.get_figure()\n",
    "plt.tight_layout = True\n",
    "plt.show()\n",
    "fig.savefig(\n",
    "    f\"src/main/rl/evaluation/plot_results/phase3_rewards_per_combi.png\",\n",
    "    format=\"png\",\n",
    "    dpi=300,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d00ee1d-ab1e-4f39-86fe-49f294273c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistics per combination\n",
    "from scipy.stats import iqr\n",
    "\n",
    "df_statistics_per_combination = (\n",
    "    df.drop(columns=[\"full_path\"])\n",
    "    .groupby([\"combination\", \"scenario\", \"alg\", \"action_wrapper\", \"obs_wrapper\", \"automation_wrapper\"], dropna=False)\n",
    "    .agg([\"mean\", \"max\", \"min\", \"std\", iqr])\n",
    ")\n",
    "# Necessary to set index as alphabetical is confusing for the thesis\n",
    "df_statistics_per_combination[\"index\"] = [0, 1, 3, 2, 5, 4]\n",
    "df_statistics_per_combination = (\n",
    "    df_statistics_per_combination.reset_index().set_index([\"index\", \"combination\"]).sort_index()\n",
    ")\n",
    "df_statistics_per_combination.columns = [\"_\".join(a) for a in df_statistics_per_combination.columns.to_flat_index()]\n",
    "save_df_per_combination = df_statistics_per_combination.copy()\n",
    "[col for col in df_statistics_per_combination.columns if \"time\" in col]\n",
    "df_statistics_per_combination[[\"total_timesteps_mean\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfaa4349-40d9-4383-8c5f-9dcb0f8825d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as plticker\n",
    "from src.main.rl.evaluation.plots.phase3_plots import prepare_one_combination_actions_and_obs_for_analysis\n",
    "\n",
    "path = \"src/main/rl/models/scenario3/training_04_06/scenario3_ActionSpaceOption3Wrapper_ObservationOption5Wrapper_NPPAutomationWrapper_RewardOption2Wrapper_A2C_training_04_06\"\n",
    "\n",
    "(\n",
    "    actions_prepared,\n",
    "    obs_prepared,\n",
    "    list_of_all_actions_taken,\n",
    "    list_of_all_obs_taken,\n",
    ") = prepare_one_combination_actions_and_obs_for_analysis(path, obs_dimensions=11)\n",
    "\n",
    "# Actions Analysis Combi 2\n",
    "\n",
    "scaling_factors_scenario_1 = [100, 2000, 1, 1, 2000]\n",
    "\n",
    "for idx, item in enumerate(actions_prepared):\n",
    "    item = item.fillna(4)\n",
    "    item = item.applymap(lambda x: scaling_factors_scenario_3[idx][x])\n",
    "    actions_prepared[idx] = item.agg([\"mean\", \"min\", \"max\", \"std\"], axis=1)\n",
    "    actions_prepared[idx][\"minus\"] = actions_prepared[idx][\"mean\"] - actions_prepared[idx][\"std\"]\n",
    "    actions_prepared[idx][\"plus\"] = actions_prepared[idx][\"mean\"] + actions_prepared[idx][\"std\"]\n",
    "# Actions Analysis Combi 2\n",
    "from src.main.rl.utils.constants import scaling_factors_scenario_1, action_dimensions_german\n",
    "\n",
    "fig, ax = plt.subplots(1, 5, constrained_layout=True)\n",
    "fig.set_figheight(3)\n",
    "fig.set_figwidth(20)\n",
    "[ax[idx].plot(item[\"mean\"], color=color_mapping[\"standard\"]) for idx, item in enumerate(actions_prepared)]\n",
    "# [ax[idx].fill_between([i for i in range(250)],item[\"plus\"],item[\"minus\"],color=color_mapping[\"standard\"],alpha=0.3) for idx, item in enumerate(result_list)]\n",
    "[\n",
    "    ax[idx].fill_between([i for i in range(251)], item[\"min\"], item[\"max\"], color=color_mapping[\"standard\"], alpha=0.3)\n",
    "    for idx, item in enumerate(actions_prepared)\n",
    "]\n",
    "[ax[idx].set_xlabel(\"Zeitschritte\") for idx in range(5)]\n",
    "[ax[idx].set_ylabel(\"Value\") for idx in range(5)]\n",
    "[ax[idx].set_title(action_dimensions_german[idx]) for idx in range(5)]\n",
    "\n",
    "# fig.savefig(\n",
    "#    f\"src/main/rl/evaluation/plot_results/phase3_actions_plot_with_min_max_scen1_w.png\",\n",
    "#    format=\"png\",\n",
    "#    dpi=300,\n",
    "# )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f95eda-ae98-4f12-be06-8006e05b8d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Single Reward per timestep ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5f75d9-7ec9-494c-a70d-40e63374dddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from src.main.rl.utils.parser import parse_scenario_name, parse_wrapper\n",
    "from src.main.rl.utils.combined_parser import parse_information_from_path\n",
    "from src.main.rl.evaluation.eval import get_single_reward\n",
    "\n",
    "paths = [\n",
    "    \"src/main/rl/models/scenario1/training_04_06/scenario1_ActionSpaceOption3Wrapper_ObservationOption4Wrapper_None_RewardOption2Wrapper_TD3_training_04_06\",\n",
    "    \"src/main/rl/models/scenario1/training_04_06/scenario1_ActionSpaceOption3Wrapper_ObservationOption5Wrapper_NPPAutomationWrapper_RewardOption2Wrapper_SAC_training_04_06\",\n",
    "    \"src/main/rl/models/scenario2/training_04_06/scenario2_ActionSpaceOption3Wrapper_ObservationOption5Wrapper_None_RewardOption2Wrapper_PPO_training_04_06\",\n",
    "    \"src/main/rl/models/scenario2/training_04_06/scenario2_ActionSpaceOption3Wrapper_ObservationOption4Wrapper_NPPAutomationWrapper_RewardOption2Wrapper_PPO_training_04_06\",\n",
    "    \"src/main/rl/models/scenario3/training_04_06/scenario3_ActionSpaceOption3Wrapper_ObservationOption5Wrapper_None_RewardOption2Wrapper_PPO_training_04_06\",\n",
    "    \"src/main/rl/models/scenario3/training_04_06/scenario3_ActionSpaceOption3Wrapper_ObservationOption3Wrapper_NPPAutomationWrapper_RewardOption2Wrapper_PPO_training_04_06\",\n",
    "]\n",
    "list_combinations = [pd.DataFrame() for i in range(len(paths))]\n",
    "for idx, path in enumerate(paths):\n",
    "\n",
    "    for number in range(1, 11):\n",
    "        result_dict = {}\n",
    "        full_path = path + f\"_{str(number)}\"\n",
    "        path_to_overhand = full_path + \"/best_model.zip\"\n",
    "\n",
    "        action_wrapper, automation_wrapper, obs_wrapper, reward_wrapper = parse_wrapper(full_path)\n",
    "        scenario, alg, wrapper_maker = parse_information_from_path(full_path)\n",
    "        reward = get_single_reward(scenario, path_to_overhand, alg, wrapper_maker, episode_length=250)\n",
    "        intermediate_df = pd.DataFrame()\n",
    "        intermediate_df[full_path] = reward\n",
    "        list_combinations[idx] = list_combinations[idx].join(intermediate_df, how=\"outer\")\n",
    "\n",
    "    print(list_combinations[idx].eq(1).sum().sum())\n",
    "\n",
    "for idx, item in enumerate(list_combinations):\n",
    "    list_combinations[idx] = item.agg([\"mean\", \"min\", \"max\", \"std\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b176cd-3ef3-468f-82fd-dfb6fa7e2012",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from src.main.rl.utils.constants import color_mapping\n",
    "\n",
    "fig, ax = plt.subplots(2, 3, constrained_layout=True)\n",
    "fig.set_figheight(4)\n",
    "fig.set_figwidth(10)\n",
    "[\n",
    "    ax[0][idx].plot(item[\"mean\"], color=color_mapping[\"standard\"])\n",
    "    for idx, item in enumerate(list_combinations)\n",
    "    if idx < 3\n",
    "]\n",
    "[\n",
    "    ax[1][idx - 3].plot(item[\"mean\"], color=color_mapping[\"standard\"])\n",
    "    for idx, item in enumerate(list_combinations)\n",
    "    if idx >= 3\n",
    "]\n",
    "[\n",
    "    ax[0][idx].fill_between(\n",
    "        [i for i in range(249)], item[\"min\"], item[\"max\"], color=color_mapping[\"standard\"], alpha=0.3\n",
    "    )\n",
    "    for idx, item in enumerate(list_combinations)\n",
    "    if idx < 3\n",
    "]\n",
    "[\n",
    "    ax[1][idx - 3].fill_between(\n",
    "        [i for i in range(249)], item[\"min\"], item[\"max\"], color=color_mapping[\"standard\"], alpha=0.3\n",
    "    )\n",
    "    for idx, item in enumerate(list_combinations)\n",
    "    if idx >= 3\n",
    "]\n",
    "[ax[0][idx].set_xlabel(\"Zeitschritte\") for idx in range(6) if idx < 3]\n",
    "[ax[1][idx - 3].set_xlabel(\"Zeitschritte\") for idx in range(6) if idx >= 3]\n",
    "[ax[0][idx].set_ylabel(\"Value\") for idx in range(6) if idx < 3]\n",
    "[ax[1][idx - 3].set_ylabel(\"Value\") for idx in range(6) if idx >= 3]\n",
    "[ax[0][idx].set_title(f\"Kombination {idx+1}\") for idx in range(6) if idx < 3]\n",
    "[ax[1][idx - 3].set_title(f\"Kombination {idx+1}\") for idx in range(6) if idx >= 3]\n",
    "plt.show()\n",
    "fig.savefig(\n",
    "    f\"src/main/rl/evaluation/plot_results/phase3_reward_per_step_per_combi.png\",\n",
    "    format=\"png\",\n",
    "    dpi=300,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ac8359-3a55-4398-9450-42dc04869e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, constrained_layout=True)\n",
    "fig.set_figheight(4)\n",
    "fig.set_figwidth(8)\n",
    "colors = [\n",
    "    color_mapping[\"blue\"],\n",
    "    color_mapping[\"red\"],\n",
    "    color_mapping[\"grey\"],\n",
    "    color_mapping[\"yellow\"],\n",
    "    color_mapping[\"brown\"],\n",
    "    color_mapping[\"turquoise\"],\n",
    "]\n",
    "[ax.plot(item[\"mean\"], color=colors[idx]) for idx, item in enumerate(list_combinations)]\n",
    "ax.set_xlabel(\"Zeitschritte\")\n",
    "ax.set_xlabel(\"Reward\")\n",
    "ax.set_title(f\"Durschnittlicher Reward je Zeitschritt pro Kombination\")\n",
    "plt.plot([], c=color_mapping[\"blue\"], label=\"Kombination 1\")\n",
    "plt.plot([], c=color_mapping[\"red\"], label=\"Kombination 2\")\n",
    "plt.plot([], c=color_mapping[\"grey\"], label=\"Kombination 3\")\n",
    "plt.plot([], c=color_mapping[\"yellow\"], label=\"Kombination 4\")\n",
    "plt.plot([], c=color_mapping[\"brown\"], label=\"Kombination 5\")\n",
    "plt.plot([], c=color_mapping[\"turquoise\"], label=\"Kombination 6\")\n",
    "plt.legend()\n",
    "fig.savefig(\n",
    "    f\"src/main/rl/evaluation/plot_results/phase3_reward_per_step_per_combi.png\",\n",
    "    format=\"png\",\n",
    "    dpi=300,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4fa513-a15b-415d-ac22-5b1fb026b4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Statistics over the all combinations ######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5829420c-b42d-44e2-ab8b-6ffa161d2655",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import iqr\n",
    "from src.main.rl.evaluation.phase3_evaluation import create_evaluation_df_phase3\n",
    "\n",
    "paths = [\n",
    "    \"src/main/rl/models/scenario1/training_04_06/scenario1_ActionSpaceOption3Wrapper_ObservationOption4Wrapper_None_RewardOption2Wrapper_TD3_training_04_06\",\n",
    "    \"src/main/rl/models/scenario1/training_04_06/scenario1_ActionSpaceOption3Wrapper_ObservationOption5Wrapper_NPPAutomationWrapper_RewardOption2Wrapper_SAC_training_04_06\",\n",
    "    \"src/main/rl/models/scenario2/training_04_06/scenario2_ActionSpaceOption3Wrapper_ObservationOption5Wrapper_None_RewardOption2Wrapper_PPO_training_04_06\",\n",
    "    \"src/main/rl/models/scenario2/training_04_06/scenario2_ActionSpaceOption3Wrapper_ObservationOption4Wrapper_NPPAutomationWrapper_RewardOption2Wrapper_PPO_training_04_06\",\n",
    "    \"src/main/rl/models/scenario3/training_04_06/scenario3_ActionSpaceOption3Wrapper_ObservationOption5Wrapper_None_RewardOption2Wrapper_PPO_training_04_06\",\n",
    "    \"src/main/rl/models/scenario3/training_04_06/scenario3_ActionSpaceOption3Wrapper_ObservationOption5Wrapper_NPPAutomationWrapper_RewardOption2Wrapper_A2C_training_04_06\",\n",
    "]\n",
    "path_to_save = \"src/main/rl/evaluation/output/phase3_evaluation_results_new3.csv\"\n",
    "pd.options.display.max_colwidth = 500\n",
    "df = pd.DataFrame()\n",
    "try:\n",
    "    df = pd.read_csv(path_to_save)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "if df.empty:\n",
    "    df = create_evaluation_df_phase3(path_to_save, paths)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe752db-807a-4498-9f7b-8a1a542974b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistics over the whole dataframe\n",
    "df_total1 = df.drop(\n",
    "    columns=[\"full_path\", \"combination\", \"scenario\", \"alg\", \"action_wrapper\", \"obs_wrapper\", \"automation_wrapper\"]\n",
    ").agg([\"mean\", \"max\", \"min\", \"std\"])\n",
    "df_total2 = (\n",
    "    df.drop(\n",
    "        columns=[\"full_path\", \"combination\", \"scenario\", \"alg\", \"action_wrapper\", \"obs_wrapper\", \"automation_wrapper\"]\n",
    "    )\n",
    "    .groupby(lambda x: True, dropna=True)\n",
    "    .agg([iqr])\n",
    ")\n",
    "df_total2.columns = df_total2.columns.get_level_values(0)\n",
    "df_total2[\"index\"] = \"iqr\"\n",
    "df_total = df_total1.reset_index().merge(df_total2, how=\"outer\").set_index(\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e51bf21-ab5c-4adf-94db-94ee5a4ba294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistics per combination\n",
    "df_statistics_per_combination = (\n",
    "    df.drop(columns=[\"full_path\"])\n",
    "    .groupby([\"combination\", \"scenario\", \"alg\", \"action_wrapper\", \"obs_wrapper\", \"automation_wrapper\"], dropna=False)\n",
    "    .agg([\"mean\", \"max\", \"min\", \"std\", iqr])\n",
    ")\n",
    "# Necessary to set index as alphabetical is confusing for the thesis\n",
    "df_statistics_per_combination[\"index\"] = [0, 1, 3, 2, 5, 4]\n",
    "df_statistics_per_combination = (\n",
    "    df_statistics_per_combination.reset_index().set_index([\"index\", \"combination\"]).sort_index()\n",
    ")\n",
    "df_statistics_per_combination.columns = [\"_\".join(a) for a in df_statistics_per_combination.columns.to_flat_index()]\n",
    "save_df_per_combination = df_statistics_per_combination.copy()\n",
    "df_statistics_per_combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e49f539-e91a-4b18-aa88-32dcb8156637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criticality Score per combination\n",
    "print(df_statistics_per_combination[[\"criticality_score_mean\"]].round(2))\n",
    "print(\n",
    "    df_statistics_per_combination[\n",
    "        [\n",
    "            \"criticality_score_mean\",\n",
    "            \"criticality_score_max\",\n",
    "            \"criticality_score_min\",\n",
    "            \"criticality_score_std\",\n",
    "            \"criticality_score_iqr\",\n",
    "        ]\n",
    "    ]\n",
    "    .droplevel(1)\n",
    "    .transpose()\n",
    "    .round(2)\n",
    "    .to_latex()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928462a2-35ca-4b0e-92f3-a7a26d5ca325",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7b2e35-a5f2-44a4-9be5-1860f1a2bc43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62b19a8-b8cc-4391-897c-7456c780b02b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
