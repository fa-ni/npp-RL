{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ccfe2c1-322b-4d1c-bb5a-9a8e79b702b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook is used to evaluate all created models. For the thesis this is phase 2.\n",
    "# It also shows a lot of statistics about different aspects of all trained models.\n",
    "# It also prints the \"erfolgreiche Kombinationen\".\n",
    "# Much more is possible to do with the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112c3d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate all 2400 models (reward + criticality score) - either read in already created file or create file and use df\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "from src.main.rl.evaluation.phase2_evaluation import create_evaluation_df_phase2\n",
    "\n",
    "path_to_save = \"src/main/rl/evaluation/output/phase2_evaluation_results.csv\"\n",
    "os.makedirs(\"src/main/rl/evaluation/output/\", exist_ok=True)\n",
    "os.makedirs(\"src/main/rl/evaluation/plot_results/\", exist_ok=True)\n",
    "pd.options.display.max_colwidth = 300\n",
    "\n",
    "df = pd.DataFrame()\n",
    "try:\n",
    "    df = pd.read_csv(path_to_save)\n",
    "except:\n",
    "    pass\n",
    "if df.empty:\n",
    "    all_files = []\n",
    "    for file in glob.glob(\"src/main/rl/models/*/*/*/*.zip\", recursive=True):\n",
    "        all_files.append(file)\n",
    "    create_evaluation_df_phase2(path_to_save, all_files)\n",
    "    df = pd.read_csv(path_to_save)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a9b196-3553-4b5a-a931-9462acaa6150",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wo_automation = df.query(\"automation_wrapper.isna() == True\")\n",
    "df_w_automation = df[df[\"automation_wrapper\"] == \"NPPAutomationWrapper\"]\n",
    "assert len(df_wo_automation) == len(df_wo_automation) == 1200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f642c4d4-88da-43bc-8854-e20798639e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Created aggreagted metrics with NPPAutotmation activated and deactivated\n",
    "from scipy.stats import iqr\n",
    "\n",
    "statistics_wo = (\n",
    "    df_wo_automation.set_index(\"full_path\")\n",
    "    .groupby(\"combination\")\n",
    "    .agg(\n",
    "        return_mean=(\"cum_reward\", \"mean\"),\n",
    "        return_max=(\"cum_reward\", \"max\"),\n",
    "        return_min=(\"cum_reward\", \"min\"),\n",
    "        return_std=(\"cum_reward\", \"std\"),\n",
    "        timesteps_min=(\"total_timesteps\", \"min\"),\n",
    "        scenario=(\"scenario\", \"first\"),\n",
    "        alg=(\"alg\", \"first\"),\n",
    "        action_wrapper=(\"action_wrapper\", \"first\"),\n",
    "        obs_wrapper=(\"obs_wrapper\", \"first\"),\n",
    "        automation_wrapper=(\"automation_wrapper\", \"first\"),\n",
    "    )\n",
    ")\n",
    "\n",
    "statistics_w = (\n",
    "    df_w_automation.set_index(\"full_path\")\n",
    "    .groupby(\"combination\")\n",
    "    .agg(\n",
    "        return_mean=(\"cum_reward\", \"mean\"),\n",
    "        return_max=(\"cum_reward\", \"max\"),\n",
    "        return_min=(\"cum_reward\", \"min\"),\n",
    "        return_std=(\"cum_reward\", \"std\"),\n",
    "        return_iqr=(\"cum_reward\", iqr),\n",
    "        timesteps_min=(\"total_timesteps\", \"min\"),\n",
    "        scenario=(\"scenario\", \"first\"),\n",
    "        alg=(\"alg\", \"first\"),\n",
    "        action_wrapper=(\"action_wrapper\", \"first\"),\n",
    "        obs_wrapper=(\"obs_wrapper\", \"first\"),\n",
    "        automation_wrapper=(\"automation_wrapper\", \"first\"),\n",
    "    )\n",
    ")\n",
    "assert len(statistics_wo) == 120\n",
    "assert len(statistics_w) == 120\n",
    "\n",
    "statistics_wo.merge(statistics_w, how=\"outer\").sort_values(\"return_mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee738569-10f1-4e00-95b6-6f56302c823c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create scatter plots with std and max return per combination\n",
    "from src.main.rl.evaluation.plots.phase2_plots import (\n",
    "    create_multi_object_plot,\n",
    "    create_phase_2_counts_plots,\n",
    ")\n",
    "\n",
    "figures = create_multi_object_plot(statistics_wo.merge(statistics_w, how=\"outer\"))\n",
    "for idx, fig in enumerate(figures):\n",
    "    fig.savefig(\n",
    "        f\"src/main/rl/evaluation/plot_results/phase2_summary_plots{idx}.png\",\n",
    "        format=\"png\",\n",
    "        dpi=300,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b980a4a2-e353-48fb-8864-6eb48862d391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get highest returns overall\n",
    "highest_return_wo_automation = df_wo_automation.query(\"cum_reward == cum_reward.max()\")\n",
    "print(highest_return_wo_automation[[\"cum_reward\", \"combination\"]])\n",
    "highest_return_w_automation = df_w_automation.query(\"cum_reward == cum_reward.max()\")\n",
    "print(highest_return_w_automation[[\"cum_reward\", \"combination\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0c931f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Highest return of scenario 2\n",
    "df_all = statistics_wo.merge(statistics_w, how=\"outer\")\n",
    "df_all.query(\"scenario=='scenario2'\")[\"return_max\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e0189e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Info about the combination with the highest standard deviation\n",
    "statistics_wo.merge(statistics_w, how=\"outer\").sort_values(\"return_std\").iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc382cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of combiantions with return STD under 15\n",
    "len(df_all.query(\"return_std<15\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c140127b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of combiantions with return STD over 80\n",
    "len(df_all.query(\"return_std>80\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d12963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimum STD\n",
    "min_std = df_all[\"return_std\"].min()\n",
    "df_all.query(\"return_std==@min_std\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a2bd93-35d0-4b35-a1a4-3075092a6db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create statistics on df without automation for different groups e.g obs_wrapper, scenario\n",
    "for item in [\"obs_wrapper\", \"scenario\", \"action_wrapper\", \"alg\"]:\n",
    "    df_special = (\n",
    "        df_wo_automation.groupby(item)\n",
    "        .agg(\n",
    "            return_mean=(\"cum_reward\", \"mean\"),\n",
    "            return_max=(\"cum_reward\", \"max\"),\n",
    "            return_std=(\"cum_reward\", \"std\"),\n",
    "            return_median=(\"cum_reward\", \"median\"),\n",
    "            return_iqr=(\"cum_reward\", iqr),\n",
    "        )\n",
    "        .round(2)\n",
    "    )\n",
    "    print(df_special)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e12e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create statistics on df with automation for different groups e.g obs_wrapper, scenario\n",
    "for item in [\"obs_wrapper\", \"scenario\", \"action_wrapper\", \"alg\"]:\n",
    "    df_special = (\n",
    "        df_w_automation.groupby(item)\n",
    "        .agg(\n",
    "            return_mean=(\"cum_reward\", \"mean\"),\n",
    "            return_max=(\"cum_reward\", \"max\"),\n",
    "            return_std=(\"cum_reward\", \"std\"),\n",
    "            return_median=(\"cum_reward\", \"median\"),\n",
    "            return_iqr=(\"cum_reward\", iqr),\n",
    "        )\n",
    "        .round(2)\n",
    "    )\n",
    "    print(df_special)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd19a3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of return via histogram\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "from src.main.rl.utils.constants import color_mapping\n",
    "\n",
    "n, bins, patches = plt.hist(\n",
    "    df[\"cum_reward\"],\n",
    "    10,\n",
    "    facecolor=color_mapping[\"blue\"],\n",
    "    weights=np.ones(len(df)) / len(df),\n",
    ")\n",
    "plt.gca().yaxis.set_major_formatter(PercentFormatter(1))\n",
    "plt.xlabel(\"Return\")\n",
    "plt.ylabel(\"Number of Models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1ad352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histograms per alg\n",
    "\n",
    "algs = [\n",
    "    \"<class 'stable_baselines3.sac.sac.SAC'>\",\n",
    "    \"<class 'stable_baselines3.td3.td3.TD3'>\",\n",
    "    \"<class 'stable_baselines3.a2c.a2c.A2C'>\",\n",
    "    \"<class 'stable_baselines3.ppo.ppo.PPO'>\",\n",
    "]\n",
    "algs_correct = [\"SAC\", \"TD3\", \"A2C\", \"PPO\"]\n",
    "for idx, item in enumerate(algs):\n",
    "    temp_df = df[df[\"alg\"] == item][\"cum_reward\"]\n",
    "    n, bins, patches = plt.hist(\n",
    "        temp_df,\n",
    "        10,\n",
    "        facecolor=color_mapping[\"blue\"],\n",
    "        weights=np.ones(len(temp_df)) / len(temp_df),\n",
    "    )\n",
    "    plt.title(algs_correct[idx])\n",
    "    plt.gca().yaxis.set_major_formatter(PercentFormatter(1))\n",
    "    plt.xlabel(\"Return\")\n",
    "    plt.ylabel(\"Anzahl an Modellen\")\n",
    "    plt.savefig(\n",
    "        f\"src/main/rl/evaluation/plot_results/phase2_histogram_{idx}.png\",\n",
    "        format=\"png\",\n",
    "        dpi=300,\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0935c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normal distribution test\n",
    "from scipy.stats import normaltest\n",
    "\n",
    "print(\n",
    "    normaltest(df[df[\"alg\"] == \"<class 'stable_baselines3.td3.td3.TD3'>\"][\"cum_reward\"])\n",
    ")\n",
    "print(\n",
    "    normaltest(df[df[\"alg\"] == \"<class 'stable_baselines3.ppo.ppo.PPO'>\"][\"cum_reward\"])\n",
    ")\n",
    "print(\n",
    "    normaltest(df[df[\"alg\"] == \"<class 'stable_baselines3.a2c.a2c.A2C'>\"][\"cum_reward\"])\n",
    ")\n",
    "print(\n",
    "    normaltest(df[df[\"alg\"] == \"<class 'stable_baselines3.sac.sac.SAC'>\"][\"cum_reward\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8d1fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normal distribution test\n",
    "from scipy.stats import shapiro\n",
    "\n",
    "print(shapiro(df[df[\"alg\"] == \"<class 'stable_baselines3.td3.td3.TD3'>\"][\"cum_reward\"]))\n",
    "print(shapiro(df[df[\"alg\"] == \"<class 'stable_baselines3.ppo.ppo.PPO'>\"][\"cum_reward\"]))\n",
    "print(shapiro(df[df[\"alg\"] == \"<class 'stable_baselines3.a2c.a2c.A2C'>\"][\"cum_reward\"]))\n",
    "print(shapiro(df[df[\"alg\"] == \"<class 'stable_baselines3.sac.sac.SAC'>\"][\"cum_reward\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8af77e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two-sample Kolmogorov-Smirnov\n",
    "from scipy.stats import ks_2samp\n",
    "\n",
    "algs = [\n",
    "    \"<class 'stable_baselines3.td3.td3.TD3'>\",\n",
    "    \"<class 'stable_baselines3.ppo.ppo.PPO'>\",\n",
    "    \"<class 'stable_baselines3.a2c.a2c.A2C'>\",\n",
    "    \"<class 'stable_baselines3.sac.sac.SAC'>\",\n",
    "]\n",
    "for item in algs:\n",
    "    for item2 in algs:\n",
    "        if item != item2:\n",
    "            print(item, item2)\n",
    "            print(\n",
    "                ks_2samp(\n",
    "                    df[df[\"alg\"] == item][\"cum_reward\"],\n",
    "                    df[df[\"alg\"] == item2][\"cum_reward\"],\n",
    "                )\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f741d6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actually not really allowed as data is non-normal. Just used as indication and with big sample size.\n",
    "# Also note that a correction factor would be necessary as we do many comparisons.\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "algs = [\n",
    "    \"<class 'stable_baselines3.td3.td3.TD3'>\",\n",
    "    \"<class 'stable_baselines3.ppo.ppo.PPO'>\",\n",
    "    \"<class 'stable_baselines3.a2c.a2c.A2C'>\",\n",
    "    \"<class 'stable_baselines3.sac.sac.SAC'>\",\n",
    "]\n",
    "for item in algs:\n",
    "    for item2 in algs:\n",
    "        if item != item2:\n",
    "            print(item, item2)\n",
    "            print(\n",
    "                ttest_ind(\n",
    "                    df[df[\"alg\"] == item][\"cum_reward\"],\n",
    "                    df[df[\"alg\"] == item2][\"cum_reward\"],\n",
    "                )\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56933be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histograms per scenario\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "scen = [\"scenario1\", \"scenario2\", \"scenario3\"]\n",
    "scenarios_correct = [\"Szenario 1\", \"Szenario 2\", \"Szenario 3\"]\n",
    "for idx, item in enumerate(scen):\n",
    "    temp_df = df[df[\"scenario\"] == item][\"cum_reward\"]\n",
    "    n, bins, patches = plt.hist(\n",
    "        temp_df,\n",
    "        10,\n",
    "        facecolor=color_mapping[\"blue\"],\n",
    "        weights=np.ones(len(temp_df)) / len(temp_df),\n",
    "    )\n",
    "    plt.title(scenarios_correct[idx])\n",
    "    plt.xlabel(\"Return\")\n",
    "    plt.ylabel(\"Number of Models\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d64474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normal distribution test\n",
    "from scipy.stats import normaltest\n",
    "\n",
    "print(normaltest(df[df[\"scenario\"] == \"scenario1\"][\"cum_reward\"]))\n",
    "print(normaltest(df[df[\"scenario\"] == \"scenario2\"][\"cum_reward\"]))\n",
    "print(normaltest(df[df[\"scenario\"] == \"scenario3\"][\"cum_reward\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c10e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normal distribution test\n",
    "from scipy.stats import shapiro\n",
    "\n",
    "print(shapiro(df[df[\"scenario\"] == \"scenario1\"][\"cum_reward\"]))\n",
    "print(shapiro(df[df[\"scenario\"] == \"scenario2\"][\"cum_reward\"]))\n",
    "print(shapiro(df[df[\"scenario\"] == \"scenario3\"][\"cum_reward\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c03cf00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two-sample Kolmogorov-Smirnov\n",
    "from scipy.stats import ks_2samp\n",
    "\n",
    "print(\n",
    "    ks_2samp(\n",
    "        df[df[\"scenario\"] == \"scenario1\"][\"cum_reward\"],\n",
    "        df[df[\"scenario\"] == \"scenario2\"][\"cum_reward\"],\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    ks_2samp(\n",
    "        df[df[\"scenario\"] == \"scenario1\"][\"cum_reward\"],\n",
    "        df[df[\"scenario\"] == \"scenario3\"][\"cum_reward\"],\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    ks_2samp(\n",
    "        df[df[\"scenario\"] == \"scenario2\"][\"cum_reward\"],\n",
    "        df[df[\"scenario\"] == \"scenario3\"][\"cum_reward\"],\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb23af21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actually not really allowed as data is non-normal. Just used as indication and with big sample size.\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "print(\n",
    "    ttest_ind(\n",
    "        df[df[\"scenario\"] == \"scenario3\"][\"cum_reward\"],\n",
    "        df[df[\"scenario\"] == \"scenario2\"][\"cum_reward\"],\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    ttest_ind(\n",
    "        df[df[\"scenario\"] == \"scenario1\"][\"cum_reward\"],\n",
    "        df[df[\"scenario\"] == \"scenario2\"][\"cum_reward\"],\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    ttest_ind(\n",
    "        df[df[\"scenario\"] == \"scenario1\"][\"cum_reward\"],\n",
    "        df[df[\"scenario\"] == \"scenario3\"][\"cum_reward\"],\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b716f8e2-3c4b-4ea1-963e-9d5724e7bd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# T-tests (Welch) - no normality of most data therefore needs to be taken with care + no correction factor for multiple tests here\n",
    "from scipy.stats import ttest_ind\n",
    "from scipy import stats\n",
    "from scipy.stats import shapiro\n",
    "\n",
    "scen1 = df.query(\"scenario=='scenario1'\")[\"cum_reward\"]\n",
    "scen2 = df.query(\"scenario=='scenario2'\")[\"cum_reward\"]\n",
    "scen3 = df.query(\"scenario=='scenario3'\")[\"cum_reward\"]\n",
    "\n",
    "stats, p = shapiro(scen1)\n",
    "print(p)\n",
    "\n",
    "print(ttest_ind(scen1, scen3, equal_var=False))\n",
    "print(ttest_ind(scen1, scen2, equal_var=False))\n",
    "print(ttest_ind(scen3, scen2, equal_var=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ac805d-27e4-4e1b-9908-864df248f9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combiniation that are \"Successfull\" per definition without automation\n",
    "paths_that_fulfil_condition_wo_automation = statistics_wo.query(\n",
    "    \"return_max>200 and return_std<15 and timesteps_min==250\"\n",
    ")\n",
    "len(paths_that_fulfil_condition_wo_automation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8f5eff-29f4-4757-a7aa-5533a9d75bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combiniation that are \"Successfull\" per definition with automation\n",
    "paths_that_fulfil_condition_w_automation = statistics_w.query(\n",
    "    \"return_max>200 and return_std<15 and timesteps_min==250\"\n",
    ")\n",
    "len(paths_that_fulfil_condition_w_automation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb4cb92-6dd4-40c3-aff1-6783095815bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a plot with all the counts of successfull combinations\n",
    "from src.main.rl.evaluation.plots.phase2_plots import (\n",
    "    create_multi_object_plot,\n",
    "    create_phase_2_counts_plots,\n",
    ")\n",
    "\n",
    "fig = create_phase_2_counts_plots(\n",
    "    paths_that_fulfil_condition_wo_automation.merge(\n",
    "        paths_that_fulfil_condition_w_automation, how=\"outer\"\n",
    "    )\n",
    ")\n",
    "fig.savefig(\n",
    "    f\"src/main/rl/evaluation/plot_results/phase2_count_plots.png\",\n",
    "    format=\"png\",\n",
    "    dpi=300,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba57cca8-a930-41a4-8efa-47ab7db7a045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get counts of different things for successfull combiniations\n",
    "cols_to_count = [\n",
    "    \"alg\",\n",
    "    \"scenario\",\n",
    "    \"action_wrapper\",\n",
    "    \"obs_wrapper\",\n",
    "    \"automation_wrapper\",\n",
    "]\n",
    "statistics_wo_value_counts = pd.Series()\n",
    "statistics_w_value_counts = pd.Series()\n",
    "for col in cols_to_count:\n",
    "    statistics_wo_value_counts = pd.concat(\n",
    "        [\n",
    "            statistics_wo_value_counts,\n",
    "            paths_that_fulfil_condition_wo_automation[col].value_counts(),\n",
    "        ]\n",
    "    )\n",
    "    statistics_w_value_counts = pd.concat(\n",
    "        [\n",
    "            statistics_w_value_counts,\n",
    "            paths_that_fulfil_condition_w_automation[col].value_counts(),\n",
    "        ]\n",
    "    )\n",
    "print(statistics_wo_value_counts)\n",
    "print(statistics_w_value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77eddeeb-5462-4306-9fed-c149654ab37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get successfull combiniations split by scenario/nppautomation and using action space option 3\n",
    "wo_automation_scenario1_action_space3 = paths_that_fulfil_condition_wo_automation.query(\n",
    "    \"scenario=='scenario1' and action_wrapper=='ActionSpaceOption3Wrapper' and timesteps_min==250\"\n",
    ")\n",
    "wo_automation_scenario2_action_space3 = paths_that_fulfil_condition_wo_automation.query(\n",
    "    \"scenario=='scenario2' and action_wrapper=='ActionSpaceOption3Wrapper' and timesteps_min==250\"\n",
    ")\n",
    "wo_automation_scenario3_action_space3 = paths_that_fulfil_condition_wo_automation.query(\n",
    "    \"scenario=='scenario3' and action_wrapper=='ActionSpaceOption3Wrapper' and timesteps_min==250\"\n",
    ")\n",
    "w_automation_scenario1_action_space3 = paths_that_fulfil_condition_w_automation.query(\n",
    "    \"scenario=='scenario1' and action_wrapper=='ActionSpaceOption3Wrapper' and timesteps_min==250\"\n",
    ")\n",
    "w_automation_scenario2_action_space3 = paths_that_fulfil_condition_w_automation.query(\n",
    "    \"scenario=='scenario2' and action_wrapper=='ActionSpaceOption3Wrapper' and timesteps_min==250\"\n",
    ")\n",
    "w_automation_scenario3_action_space3 = paths_that_fulfil_condition_w_automation.query(\n",
    "    \"scenario=='scenario3' and action_wrapper=='ActionSpaceOption3Wrapper' and timesteps_min==250\"\n",
    ")\n",
    "print(\n",
    "    f\"Only ActionSpace3 and scenario1 without automation:\\n {wo_automation_scenario1_action_space3[['return_max', 'return_mean']]}\"\n",
    ")\n",
    "print(\n",
    "    f\"Only ActionSpace3 and scenario2 without automation:\\n {wo_automation_scenario2_action_space3[['return_max', 'return_mean']]}\"\n",
    ")\n",
    "print(\n",
    "    f\"Only ActionSpace3 and scenario3 without automation:\\n {wo_automation_scenario3_action_space3[['return_max', 'return_mean']]}\"\n",
    ")\n",
    "print(\n",
    "    f\"Only ActionSpace3 and scenario1 with automation:\\n {w_automation_scenario1_action_space3[['return_max', 'return_mean', ]]}\"\n",
    ")\n",
    "print(\n",
    "    f\"Only ActionSpace3 and scenario2 with automation:\\n {w_automation_scenario2_action_space3[['return_max', 'return_mean', ]]}\"\n",
    ")\n",
    "print(\n",
    "    f\"Only ActionSpace3 and scenario3 with automation:\\n {w_automation_scenario3_action_space3[['return_max', 'return_mean', ]]}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e92ed84-f696-46fe-9424-e72bd5734a0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# All TD3 combinations\n",
    "statistics_wo[statistics_wo[\"alg\"] == \"<class 'stable_baselines3.td3.td3.TD3'>\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704ff19c-c3ae-4905-b5a1-e110600a2044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average STD per Combiniation per Algorithm\n",
    "sac = (\n",
    "    df[df[\"alg\"] == \"<class 'stable_baselines3.sac.sac.SAC'>\"]\n",
    "    .groupby(\"combination\")\n",
    "    .agg(\"std\")[\"cum_reward\"]\n",
    "    .mean()\n",
    "    .round(2)\n",
    ")\n",
    "td3 = (\n",
    "    df[df[\"alg\"] == \"<class 'stable_baselines3.td3.td3.TD3'>\"]\n",
    "    .groupby(\"combination\")\n",
    "    .agg(\"std\")[\"cum_reward\"]\n",
    "    .mean()\n",
    "    .round(2)\n",
    ")\n",
    "a2c = (\n",
    "    df[df[\"alg\"] == \"<class 'stable_baselines3.a2c.a2c.A2C'>\"]\n",
    "    .groupby(\"combination\")\n",
    "    .agg(\"std\")[\"cum_reward\"]\n",
    "    .mean()\n",
    "    .round(2)\n",
    ")\n",
    "ppo = (\n",
    "    df[df[\"alg\"] == \"<class 'stable_baselines3.ppo.ppo.PPO'>\"]\n",
    "    .groupby(\"combination\")\n",
    "    .agg(\"std\")[\"cum_reward\"]\n",
    "    .mean()\n",
    "    .round(2)\n",
    ")\n",
    "print(f\"SAC: {sac}, TD3: {td3}, A2C: {a2c}, PPO: {ppo}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d82da6-4d6a-4218-b472-44bc221a5ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average STD per Combiniation per scenario\n",
    "scen1 = (\n",
    "    df[df[\"scenario\"] == \"scenario1\"]\n",
    "    .groupby(\"combination\")\n",
    "    .agg(\"std\")[\"cum_reward\"]\n",
    "    .std()\n",
    ")\n",
    "scen2 = (\n",
    "    df[df[\"scenario\"] == \"scenario2\"]\n",
    "    .groupby(\"combination\")\n",
    "    .agg(\"std\")[\"cum_reward\"]\n",
    "    .std()\n",
    ")\n",
    "scen3 = (\n",
    "    df[df[\"scenario\"] == \"scenario3\"]\n",
    "    .groupby(\"combination\")\n",
    "    .agg(\"std\")[\"cum_reward\"]\n",
    "    .std()\n",
    ")\n",
    "print(f\"Scenario 1: {scen1}, Scenario 2: {scen2}, Scenario 3: {scen3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e545c30-6a2e-481e-802f-7955d3de6245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average STD per Combiniation per NPPAutomation\n",
    "w_auto = (\n",
    "    df[df[\"automation_wrapper\"] == \"NPPAutomationWrapper\"]\n",
    "    .groupby(\"combination\")\n",
    "    .agg(\"std\")[\"cum_reward\"]\n",
    "    .mean()\n",
    ")\n",
    "wo_auto = (\n",
    "    df[df[\"automation_wrapper\"].isna()]\n",
    "    .groupby(\"combination\")\n",
    "    .agg(\"std\")[\"cum_reward\"]\n",
    "    .mean()\n",
    ")\n",
    "print(w_auto, wo_auto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf0572b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing single results per combiniation (from each of the ten models)\n",
    "df[\n",
    "    df[\"combination\"].str.contains(\n",
    "        \"scenario1_ActionSpaceOption3Wrapper_ObservationOption5Wrapper_NPPAutomationWrapper_RewardOption2Wrapper_TD3\"\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3118387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How often were all timesteps fully done per scenario - keep in mind that scenario 1 had double as many combiniations\n",
    "# scenario 1\n",
    "df[df[\"scenario\"] == \"scenario1\"][\"total_timesteps\"].eq(250).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6f1ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scenario 2\n",
    "df[df[\"scenario\"] == \"scenario2\"][\"total_timesteps\"].eq(250).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9edab0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "## scenario 3\n",
    "df[df[\"scenario\"] == \"scenario3\"][\"total_timesteps\"].eq(250).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021abe83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How often was the return above 200 per scenario\n",
    "# scenario 1\n",
    "len(df.query(\"scenario == 'scenario1' and cum_reward>200\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439c707d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scenario 2\n",
    "len(df.query(\"scenario == 'scenario2' and cum_reward>200\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b77c713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scenario 3\n",
    "len(df.query(\"scenario == 'scenario3' and cum_reward>200\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401f1906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count combinations with STD under 15 per scenario\n",
    "# scenario 1\n",
    "scen = df[df[\"scenario\"] == \"scenario1\"].groupby(\"combination\").agg(\"std\")\n",
    "(scen[\"cum_reward\"] < 15).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef89cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scenario 2\n",
    "scen = df[df[\"scenario\"] == \"scenario2\"].groupby(\"combination\").agg(\"std\")[\"cum_reward\"]\n",
    "(scen < 15).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5eaf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scenario 3\n",
    "scen = df[df[\"scenario\"] == \"scenario3\"].groupby(\"combination\").agg(\"std\")[\"cum_reward\"]\n",
    "(scen < 15).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a929133a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there are outliers for the return in the successful combinations\n",
    "df_success = statistics_wo.merge(statistics_w, how=\"outer\").query(\n",
    "    \"timesteps_min==250 and return_max>200 and return_std<15\"\n",
    ")\n",
    "df_success[\"diff_mean_min\"] = abs(df_success[\"return_mean\"] - df_success[\"return_min\"])\n",
    "print(df_success[\"diff_mean_min\"].sort_values())\n",
    "df_success[\"diff_mean_min\"].sort_values().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aed9462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same for unsuccessful combinations\n",
    "df_success = statistics_wo.merge(statistics_w, how=\"outer\").query(\n",
    "    \"~(timesteps_min==250 and return_max>200 and return_std<15)\"\n",
    ")\n",
    "df_success[\"diff_mean_min\"] = abs(df_success[\"return_mean\"] - df_success[\"return_min\"])\n",
    "print(df_success[\"diff_mean_min\"].sort_values())\n",
    "print(df_success[\"diff_mean_min\"].sort_values().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd1964f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sparse Rewards\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "from src.main.rl.evaluation.phase2_evaluation import create_evaluation_df_phase2\n",
    "\n",
    "path_to_save = (\n",
    "    \"src/main/rl/evaluation/output/phase2_evaluation_results_sparse_rewards.csv\"\n",
    ")\n",
    "os.makedirs(\"src/main/rl/evaluation/output/\", exist_ok=True)\n",
    "os.makedirs(\"src/main/rl/evaluation/plot_results/\", exist_ok=True)\n",
    "pd.options.display.max_colwidth = 300\n",
    "\n",
    "df = pd.DataFrame()\n",
    "try:\n",
    "    df = pd.read_csv(path_to_save)\n",
    "except:\n",
    "    pass\n",
    "if df.empty:\n",
    "    all_files = []\n",
    "    for file in glob.glob(\n",
    "        \"src/main/rl/models_sparse_rewards/*/*/*/*.zip\", recursive=True\n",
    "    ):\n",
    "        all_files.append(file)\n",
    "    create_evaluation_df_phase2(path_to_save, all_files)\n",
    "    df = pd.read_csv(path_to_save)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ee2904",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
