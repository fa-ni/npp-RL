{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656c3db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook is used to plot some of the training curves and also calculate the wall times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0dd337f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from src.main.rl.utils.constants import color_mapping\n",
    "import pandas as pd\n",
    "import glob\n",
    "from tbparse import SummaryReader\n",
    "\n",
    "from src.main.rl.utils.parser import parse_alg_name\n",
    "\n",
    "df_times = pd.DataFrame()\n",
    "try:\n",
    "    df_times = pd.read_csv(\"src/main/rl/evaluation/output/execution_times.csv\")\n",
    "except:\n",
    "    pass\n",
    "if df_times.empty:\n",
    "    all_files = []\n",
    "    for file in glob.glob(\"src/main/rl/logs/*/*/*/*\", recursive=True):\n",
    "        all_files.append(file)\n",
    "\n",
    "    result_dict = {}\n",
    "    for item in all_files:\n",
    "        reader = SummaryReader(item, extra_columns={\"wall_time\"})\n",
    "        df_times = reader.scalars\n",
    "        df_times[\"wall_time\"] = pd.to_datetime(df_times[\"wall_time\"], unit=\"s\")\n",
    "        time_diff = (\n",
    "            df_times[\"wall_time\"].max() - df_times[\"wall_time\"].min()\n",
    "        ).total_seconds()\n",
    "        result_dict[item] = [time_diff, parse_alg_name(item)]\n",
    "    df_times = pd.DataFrame.from_dict(\n",
    "        result_dict, orient=\"index\", columns=[\"seconds\", \"alg\"]\n",
    "    )\n",
    "    df_times.to_csv(\"src/main/rl/evaluation/output/execution_times.csv\")\n",
    "\n",
    "df_times.groupby(\"alg\").agg([\"mean\", \"sum\"]) / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33777984",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = []\n",
    "for file in glob.glob(\"src/main/rl/logs/*/*/*TD3*/*\", recursive=True):\n",
    "    all_files.append(file)\n",
    "\n",
    "chosen_iterations = [18, 32, 110, 289]\n",
    "chosen_files = [all_files[i] for i in chosen_iterations]\n",
    "result_dict = {}\n",
    "fig, ax = plt.subplots(constrained_layout=True, figsize=(6, 3))\n",
    "fig.set_dpi(300)\n",
    "for idx, item in enumerate(chosen_files):\n",
    "    reader = SummaryReader(item, extra_columns={\"dir_name\", \"file_name\"})\n",
    "    df = reader.scalars\n",
    "    df = df.query(\"tag=='eval/mean_reward'\")\n",
    "    plt.plot(df[\"step\"], df[\"value\"], list(color_mapping.values())[idx])\n",
    "    ax.xaxis.set_major_formatter(\n",
    "        matplotlib.ticker.FuncFormatter(\n",
    "            lambda x, p: format(int(x), \",\").replace(\",\", \".\")\n",
    "        )\n",
    "    )\n",
    "    plt.xlabel(\"Zeitschritte\")\n",
    "    plt.ylabel(\"Return\")\n",
    "plt.show()\n",
    "fig.savefig(\n",
    "    f\"src/main/rl/evaluation/plot_results/phase2training_td3.png\",\n",
    "    format=\"png\",\n",
    "    dpi=300,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a76b66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = []\n",
    "for file in glob.glob(\"src/main/rl/logs/*/*/*PPO*/*\", recursive=True):\n",
    "    all_files.append(file)\n",
    "\n",
    "chosen_iterations = [140, 182, 284, 494, 584, 843]\n",
    "chosen_files = [all_files[i] for i in chosen_iterations]\n",
    "result_dict = {}\n",
    "fig, ax = plt.subplots(constrained_layout=True, figsize=(6, 3))\n",
    "fig.set_dpi(300)\n",
    "for idx, item in enumerate(chosen_files):\n",
    "    reader = SummaryReader(item, extra_columns={\"dir_name\", \"file_name\"})\n",
    "    df = reader.scalars\n",
    "    df = df.query(\"tag=='eval/mean_reward'\")\n",
    "    plt.plot(df[\"step\"], df[\"value\"], list(color_mapping.values())[idx])\n",
    "    ax.xaxis.set_major_formatter(\n",
    "        matplotlib.ticker.FuncFormatter(\n",
    "            lambda x, p: format(int(x), \",\").replace(\",\", \".\")\n",
    "        )\n",
    "    )\n",
    "    plt.xlabel(\"Zeitschritte\")\n",
    "    plt.ylabel(\"Return\")\n",
    "plt.show()\n",
    "fig.savefig(\n",
    "    f\"src/main/rl/evaluation/plot_results/phase2training_ppo.png\",\n",
    "    format=\"png\",\n",
    "    dpi=300,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e51c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = []\n",
    "for file in glob.glob(\"src/main/rl/logs/*/*/*A2C*/*\", recursive=True):\n",
    "    all_files.append(file)\n",
    "\n",
    "chosen_iterations = [45, 129, 192, 534, 679, 892]\n",
    "chosen_files = [all_files[i] for i in chosen_iterations]\n",
    "result_dict = {}\n",
    "fig, ax = plt.subplots(constrained_layout=True, figsize=(6, 3))\n",
    "fig.set_dpi(300)\n",
    "for idx, item in enumerate(chosen_files):\n",
    "    reader = SummaryReader(item, extra_columns={\"dir_name\", \"file_name\"})\n",
    "    df = reader.scalars\n",
    "    df = df.query(\"tag=='eval/mean_reward'\")\n",
    "    plt.plot(df[\"step\"], df[\"value\"], list(color_mapping.values())[idx])\n",
    "    ax.xaxis.set_major_formatter(\n",
    "        matplotlib.ticker.FuncFormatter(\n",
    "            lambda x, p: format(int(x), \",\").replace(\",\", \".\")\n",
    "        )\n",
    "    )\n",
    "    plt.xlabel(\"Zeitschritte\")\n",
    "    plt.ylabel(\"Return\")\n",
    "plt.show()\n",
    "fig.savefig(\n",
    "    f\"src/main/rl/evaluation/plot_results/phase2training_a2c.png\",\n",
    "    format=\"png\",\n",
    "    dpi=300,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff6ecf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = []\n",
    "for file in glob.glob(\"src/main/rl/logs/*/*/*SAC*/*\", recursive=True):\n",
    "    all_files.append(file)\n",
    "\n",
    "chosen_iterations = [3, 44, 156, 192, 248, 293]\n",
    "chosen_files = [all_files[i] for i in chosen_iterations]\n",
    "result_dict = {}\n",
    "fig, ax = plt.subplots(constrained_layout=True, figsize=(6, 3))\n",
    "fig.set_dpi(300)\n",
    "for idx, item in enumerate(chosen_files):\n",
    "    reader = SummaryReader(item, extra_columns={\"dir_name\", \"file_name\"})\n",
    "    df = reader.scalars\n",
    "    df = df.query(\"tag=='eval/mean_reward'\")\n",
    "    plt.plot(df[\"step\"], df[\"value\"], list(color_mapping.values())[idx])\n",
    "    ax.xaxis.set_major_formatter(\n",
    "        matplotlib.ticker.FuncFormatter(\n",
    "            lambda x, p: format(int(x), \",\").replace(\",\", \".\")\n",
    "        )\n",
    "    )\n",
    "    plt.xlabel(\"Zeitschritte\")\n",
    "    plt.ylabel(\"Return\")\n",
    "plt.show()\n",
    "fig.savefig(\n",
    "    f\"src/main/rl/evaluation/plot_results/phase2training_sac.png\",\n",
    "    format=\"png\",\n",
    "    dpi=300,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cfa33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sparse Rewards\n",
    "all_files_scen1 = []\n",
    "for file in glob.glob(\"src/main/rl/logs_sparse_rewards/scen1/*/*/*\", recursive=True):\n",
    "    all_files_scen1.append(file)\n",
    "all_files_scen2 = []\n",
    "for file in glob.glob(\"src/main/rl/logs_sparse_rewards/scen2/*/*/*\", recursive=True):\n",
    "    all_files_scen2.append(file)\n",
    "all_files_scen3 = []\n",
    "for file in glob.glob(\"src/main/rl/logs_sparse_rewards/scen3/*/*/*\", recursive=True):\n",
    "    all_files_scen3.append(file)\n",
    "\n",
    "\n",
    "def print_sparse_rewards_color(all_files):\n",
    "    result_dict = {}\n",
    "    fig, ax = plt.subplots(constrained_layout=True, figsize=(6, 3))\n",
    "    fig.set_dpi(300)\n",
    "    for idx, item in enumerate(all_files):\n",
    "        reader = SummaryReader(item, extra_columns={\"dir_name\", \"file_name\"})\n",
    "        df = reader.scalars\n",
    "        df = df.query(\"tag=='eval/mean_reward'\")\n",
    "        plt.plot(df[\"step\"], df[\"value\"], list(color_mapping.values())[idx])\n",
    "        ax.xaxis.set_major_formatter(\n",
    "            matplotlib.ticker.FuncFormatter(\n",
    "                lambda x, p: format(int(x) / 1000000, \",\").replace(\",\", \".\")\n",
    "            )\n",
    "        )\n",
    "        plt.xlabel(\"Zeitschritte in Millionen\")\n",
    "        plt.ylabel(\"Return\")\n",
    "    plt.show()\n",
    "    # fig.savefig(\n",
    "    #    f\"src/main/rl/evaluation/plot_results/phase1_training_scen1_sparse_rewards.png\",\n",
    "    #    format=\"png\",\n",
    "    #    dpi=300,\n",
    "    # )\n",
    "\n",
    "\n",
    "print_sparse_rewards_color(all_files_scen1)\n",
    "print_sparse_rewards_color(all_files_scen2)\n",
    "print_sparse_rewards_color(all_files_scen3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e25cbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sparse Rewards\n",
    "all_files_scen1 = []\n",
    "all_files_scen2 = []\n",
    "all_files_scen3 = []\n",
    "for file in glob.glob(\"src/main/rl/logs_sparse_rewards/scen1/*/*/*\", recursive=True):\n",
    "    all_files_scen1.append(file)\n",
    "for file in glob.glob(\"src/main/rl/logs_sparse_rewards/scen2/*/*/*\", recursive=True):\n",
    "    all_files_scen2.append(file)\n",
    "for file in glob.glob(\"src/main/rl/logs_sparse_rewards/scen3/*/*/*\", recursive=True):\n",
    "    all_files_scen3.append(file)\n",
    "\n",
    "\n",
    "def print_sparse_rewards(all_files: list, number: int):\n",
    "    result_dict = {}\n",
    "    fig, ax = plt.subplots(constrained_layout=True, figsize=(6, 3))\n",
    "    fig.set_dpi(300)\n",
    "    for idx, item in enumerate(all_files):\n",
    "        reader = SummaryReader(item, extra_columns={\"dir_name\", \"file_name\"})\n",
    "        df = reader.scalars\n",
    "        df = df.query(\"tag=='eval/mean_reward'\")\n",
    "        plt.plot(\n",
    "            df[\"step\"],\n",
    "            df[\"value\"],\n",
    "            list(color_mapping.values())[0]\n",
    "            if \"None\" in item\n",
    "            else list(color_mapping.values())[1],\n",
    "        )\n",
    "        ax.xaxis.set_major_formatter(\n",
    "            matplotlib.ticker.FuncFormatter(\n",
    "                lambda x, p: format(int(x) / 1000000, \",\").replace(\",\", \".\")\n",
    "            )\n",
    "        )\n",
    "        plt.xlabel(\"Zeitschritte in Millionen\")\n",
    "        plt.ylabel(\"Return\")\n",
    "    plt.plot([], c=color_mapping[\"yellow\"], label=f\"Kombination {number}\")\n",
    "    plt.plot([], c=color_mapping[\"red\"], label=f\"Kombination {number+1}\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    fig.savefig(\n",
    "        f\"src/main/rl/evaluation/plot_results/phase1_training_sparse_rewards_scenario{number}.png\",\n",
    "        format=\"png\",\n",
    "        dpi=300,\n",
    "    )\n",
    "\n",
    "\n",
    "print_sparse_rewards(all_files_scen1, 1)\n",
    "print_sparse_rewards(all_files_scen2, 3)\n",
    "print_sparse_rewards(all_files_scen3, 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
