{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8acfb16-0d15-41ab-928d-99e31db77858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook is used to do some general comparison between the chosen six combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8667653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preperation for obs and action plotting\n",
    "import pandas as pd\n",
    "from src.main.rl.evaluation.plots.phase3_plots import (\n",
    "    prepare_one_combination_actions_and_obs_for_analysis,\n",
    ")\n",
    "from src.main.rl.utils.constants import color_mapping\n",
    "from src.main.rl.utils.constants import (\n",
    "    scaling_factors_scenario_1,\n",
    "    scaling_factors_scenario_2,\n",
    "    scaling_factors_scenario_3,\n",
    "    action_dimensions_german,\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "paths = [\n",
    "    \"src/main/rl/models/scenario1/training_04_06/scenario1_ActionSpaceOption3Wrapper_ObservationOption4Wrapper_None_RewardOption2Wrapper_TD3_training_04_06\",\n",
    "    \"src/main/rl/models/scenario1/training_04_06/scenario1_ActionSpaceOption3Wrapper_ObservationOption5Wrapper_NPPAutomationWrapper_RewardOption2Wrapper_SAC_training_04_06\",\n",
    "    \"src/main/rl/models/scenario2/training_04_06/scenario2_ActionSpaceOption3Wrapper_ObservationOption5Wrapper_None_RewardOption2Wrapper_PPO_training_04_06\",\n",
    "    \"src/main/rl/models/scenario2/training_04_06/scenario2_ActionSpaceOption3Wrapper_ObservationOption4Wrapper_NPPAutomationWrapper_RewardOption2Wrapper_PPO_training_04_06\",\n",
    "    \"src/main/rl/models/scenario3/training_04_06/scenario3_ActionSpaceOption3Wrapper_ObservationOption5Wrapper_None_RewardOption2Wrapper_PPO_training_04_06\",\n",
    "    \"src/main/rl/models/scenario3/training_04_06/scenario3_ActionSpaceOption3Wrapper_ObservationOption3Wrapper_NPPAutomationWrapper_RewardOption2Wrapper_PPO_training_04_06\",\n",
    "]\n",
    "list_actions_prepared = []\n",
    "list_obs_prepared = []\n",
    "list_list_of_all_actions_taken = []\n",
    "list_list_of_all_obs_taken = []\n",
    "obs_dimensions = [6, 11, 11, 6, 11, 7]\n",
    "\n",
    "scaling_factors = [\n",
    "    scaling_factors_scenario_1,\n",
    "    scaling_factors_scenario_1,\n",
    "    scaling_factors_scenario_2,\n",
    "    scaling_factors_scenario_2,\n",
    "    scaling_factors_scenario_3,\n",
    "    scaling_factors_scenario_3,\n",
    "]\n",
    "for idx, path in enumerate(paths):\n",
    "    (\n",
    "        actions_prepared,\n",
    "        obs_prepared,\n",
    "        list_of_all_actions_taken,\n",
    "        list_of_all_obs_taken,\n",
    "    ) = prepare_one_combination_actions_and_obs_for_analysis(\n",
    "        path, obs_dimensions=obs_dimensions[idx]\n",
    "    )\n",
    "    list_actions_prepared.append(actions_prepared)\n",
    "    list_obs_prepared.append(obs_prepared)\n",
    "    list_list_of_all_actions_taken.append(list_of_all_actions_taken)\n",
    "    list_list_of_all_obs_taken.append(list_of_all_obs_taken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1de9ae-1f13-4eee-b441-6dc87cb6bea0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create all actions taken mean (min, max) for all 6 combis\n",
    "# Mean is dark blue line, shaded blue is the min/max from the ten models within a combiniation at that timestamp\n",
    "scaling_functions = [\n",
    "    lambda x: int(round((x + 1) * (scaling_factors[list_idx][idx] / 2))),\n",
    "    lambda x: int(round((x + 1) * (scaling_factors[list_idx][idx] / 2))),\n",
    "    lambda x: -scaling_factors_scenario_2[idx]\n",
    "    if x == 0\n",
    "    else scaling_factors_scenario_2[idx],\n",
    "    lambda x: -scaling_factors_scenario_2[idx]\n",
    "    if x == 0\n",
    "    else scaling_factors_scenario_2[idx],\n",
    "    lambda x: scaling_factors_scenario_3[idx][x],\n",
    "    lambda x: scaling_factors_scenario_3[idx][x],\n",
    "]\n",
    "for list_idx, actions_prepared in enumerate(list_actions_prepared):\n",
    "    for idx, item in enumerate(actions_prepared):\n",
    "        # actions are scaled in the models, so we need to rescale\n",
    "        item = item.applymap(scaling_functions[list_idx])\n",
    "        # get min, mean, max for plotting\n",
    "        actions_prepared[idx] = item.agg([\"mean\", \"min\", \"max\", \"std\"], axis=1)\n",
    "    fig, ax = plt.subplots(1, 5, constrained_layout=True)\n",
    "    fig.set_figheight(3)\n",
    "    fig.set_figwidth(20)\n",
    "    [\n",
    "        ax[idx].plot(item[\"mean\"], color=color_mapping[\"standard\"])\n",
    "        for idx, item in enumerate(actions_prepared)\n",
    "    ]\n",
    "    [\n",
    "        ax[idx].fill_between(\n",
    "            [i for i in range(251)],\n",
    "            item[\"min\"],\n",
    "            item[\"max\"],\n",
    "            color=color_mapping[\"standard\"],\n",
    "            alpha=0.3,\n",
    "        )\n",
    "        for idx, item in enumerate(actions_prepared)\n",
    "    ]\n",
    "    [ax[idx].set_xlabel(\"Zeitschritte\") for idx in range(5)]\n",
    "    [ax[idx].set_ylabel(\"Value\") for idx in range(5)]\n",
    "    [ax[idx].set_title(f\"Kombination {list_idx+1}\") for idx in range(5)]\n",
    "    plt.show()\n",
    "    fig.savefig(\n",
    "        f\"src/main/rl/evaluation/plot_results/phase3_actions_combi_{list_idx+1}.png\",\n",
    "        format=\"png\",\n",
    "        dpi=300,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce84d912-ec20-455e-bd3f-89565ad95d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create all obs taken mean (min, max) for all 6 combis\n",
    "# Mean is dark blue line, shaded blue is the min/max from the ten models within a combiniation at that timestamp\n",
    "from src.main.rl.utils.constants import (\n",
    "    scaling_factors_scenario_1,\n",
    "    scaling_factors_scenario_2,\n",
    "    action_dimensions_german,\n",
    "    obs_dimensions_german,\n",
    "    obs_scaling_factors,\n",
    "    obs_dimensions,\n",
    "    scaling_factors_scenario_3,\n",
    ")\n",
    "\n",
    "obs_dimensions = [6, 11, 11, 6, 11, 7]\n",
    "\n",
    "for list_idx, obs_prepared in enumerate(list_obs_prepared):\n",
    "    obs_space_size = obs_dimensions[list_idx]\n",
    "    current_obs_scaling_factors = obs_scaling_factors[obs_space_size]\n",
    "    agg_result_list_obs = [pd.DataFrame() for _ in range(obs_space_size)]\n",
    "    fig, ax = plt.subplots(1, int(obs_space_size), constrained_layout=True)\n",
    "    fig.set_figheight(3)\n",
    "    fig.set_figwidth(30)\n",
    "    for idx, item in enumerate(obs_prepared):\n",
    "        item = item.fillna(0)\n",
    "        # rescaling obs\n",
    "        item = item.applymap(\n",
    "            lambda x: int(round((x + 1) * (current_obs_scaling_factors[idx] / 2)))\n",
    "        )\n",
    "        agg_result_list_obs[idx] = item.agg([\"mean\", \"min\", \"max\", \"std\"], axis=1)\n",
    "\n",
    "    [\n",
    "        ax[idx].plot(item[\"mean\"], color=color_mapping[\"standard\"])\n",
    "        for idx, item in enumerate(agg_result_list_obs)\n",
    "    ]\n",
    "    [\n",
    "        ax[idx].fill_between(\n",
    "            [i for i in range(251)],\n",
    "            item[\"min\"],\n",
    "            item[\"max\"],\n",
    "            color=color_mapping[\"standard\"],\n",
    "            alpha=0.3,\n",
    "        )\n",
    "        for idx, item in enumerate(agg_result_list_obs)\n",
    "    ]\n",
    "    [ax[idx].set_xlabel(\"Zeitschritte\") for idx in range(obs_space_size)]\n",
    "    [ax[idx].set_ylabel(\"Value\") for idx in range(obs_space_size)]\n",
    "    [\n",
    "        ax[idx].set_title(obs_dimensions_german[obs_space_size][idx])\n",
    "        for idx in range(obs_space_size)\n",
    "    ]\n",
    "fig.savefig(\n",
    "    f\"src/main/rl/evaluation/plot_results/phase3_obs_plot_with_min_max_scen1_wo_all_models.png\",\n",
    "    format=\"png\",\n",
    "    dpi=300,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea30af55-ff8b-4507-8036-7ddf3fa8c97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create all obs taken mean (min, max) for all 6 combis\n",
    "# Mean is dark blue line, shaded blue is the min/max from the ten models within a combiniation at that timestamp\n",
    "from src.main.rl.utils.constants import (\n",
    "    scaling_factors_scenario_1,\n",
    "    scaling_factors_scenario_2,\n",
    "    action_dimensions_german,\n",
    "    obs_dimensions_german,\n",
    "    obs_scaling_factors,\n",
    "    obs_dimensions,\n",
    "    scaling_factors_scenario_3,\n",
    ")\n",
    "\n",
    "obs_dimensions = [6, 11, 11]\n",
    "fig, ax = plt.subplots(1, 3, constrained_layout=True)\n",
    "\n",
    "fig.set_figheight(3)\n",
    "for list_idx, obs_prepared in enumerate(list_obs_prepared[0:3]):\n",
    "    obs_space_size = obs_dimensions[list_idx]\n",
    "    current_obs_scaling_factors = obs_scaling_factors[obs_space_size]\n",
    "    agg_result_list_obs = [pd.DataFrame() for _ in range(obs_space_size)]\n",
    "\n",
    "    fig.set_figwidth(12)\n",
    "    for idx, item in enumerate(obs_prepared):\n",
    "        item = item.fillna(0)\n",
    "        # rescaling obs\n",
    "        item = item.applymap(\n",
    "            lambda x: int(round((x + 1) * (current_obs_scaling_factors[idx] / 2)))\n",
    "        )\n",
    "        agg_result_list_obs[idx] = item.agg([\"mean\", \"min\", \"max\", \"std\"], axis=1)\n",
    "    ax[list_idx].plot(agg_result_list_obs[1][\"mean\"], color=color_mapping[\"standard\"])\n",
    "\n",
    "    ax[list_idx].fill_between(\n",
    "        [i for i in range(251)],\n",
    "        agg_result_list_obs[1][\"min\"],\n",
    "        agg_result_list_obs[1][\"max\"],\n",
    "        color=color_mapping[\"standard\"],\n",
    "        alpha=0.3,\n",
    "    )\n",
    "\n",
    "    ax[list_idx].axhline(1500, color=color_mapping[\"orange\"], ls=\"--\")\n",
    "    ax[list_idx].axhline(2500, color=color_mapping[\"orange\"], ls=\"--\")\n",
    "    ax[list_idx].axhline(2800, color=color_mapping[\"red\"], ls=\"--\")\n",
    "    ax[list_idx].axhline(1200, color=color_mapping[\"red\"], ls=\"--\")\n",
    "    ax[list_idx].axhline(1000, color=\"black\", ls=\"--\")\n",
    "    ax[list_idx].set_xlabel(\"Zeitschritte\")\n",
    "    ax[list_idx].set_ylabel(\"Wasserlevel Reaktor\")\n",
    "    ax[list_idx].set_ylim([900, 2900])\n",
    "    ax[list_idx].set_title(f\"Kombination {list_idx+1}\")\n",
    "\n",
    "fig.savefig(\n",
    "    f\"src/main/rl/evaluation/plot_results/phase3_obs_waterlevel_reactor_3combis.png\",\n",
    "    format=\"png\",\n",
    "    dpi=300,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98484501-a9f1-42b5-8e1d-0a97faf5c9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read/Create evaluation 3 details dataframe and file\n",
    "import seaborn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from src.main.rl.evaluation.phase3_evaluation import create_evaluation_df_phase3\n",
    "\n",
    "\n",
    "path_to_save = \"src/main/rl/evaluation/output/phase3_evaluation_results.csv\"\n",
    "os.makedirs(\"src/main/rl/evaluation/output/\",exist_ok=True)\n",
    "os.makedirs(\"src/main/rl/evaluation/plot_results/\",exist_ok=True)\n",
    "pd.options.display.max_colwidth = 500\n",
    "df = pd.DataFrame()\n",
    "try:\n",
    "    df = pd.read_csv(path_to_save)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "if df.empty:\n",
    "    create_evaluation_df_phase3(path_to_save, paths)\n",
    "    df = pd.read_csv(path_to_save)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f993e3-f191-4330-abce-b2c68c596884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create stripe plot of choosen combiniations\n",
    "seaborn.set(style=\"ticks\")\n",
    "ax = seaborn.stripplot(\n",
    "    x=df[\"combination\"],\n",
    "    y=df[\"cum_reward\"],\n",
    "    jitter=0.1,\n",
    "    color=color_mapping[\"standard\"],\n",
    "    dodge=True,\n",
    "    size=6,\n",
    ")\n",
    "ax.set(xticklabels=[\"1\", \"2\", \"3\", \"4\", \"5\", \"6\"])\n",
    "ax.set_xlabel(\"Kombination\")\n",
    "ax.set_ylabel(\"Return\")\n",
    "ax.margins(x=0.1)\n",
    "ax.set(yticks=[160, 180, 200, 220, 240])\n",
    "fig = ax.get_figure()\n",
    "plt.tight_layout = True\n",
    "plt.show()\n",
    "fig.savefig(\n",
    "    f\"src/main/rl/evaluation/plot_results/phase3_rewards_per_combi.png\",\n",
    "    format=\"png\",\n",
    "    dpi=300,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ace7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create boxplots with returns\n",
    "import matplotlib.pyplot as plt\n",
    "from src.main.rl.utils.constants import color_mapping\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "\n",
    "def set_box_color(bp, color):\n",
    "    plt.setp(bp[\"boxes\"], color=color)\n",
    "    plt.setp(bp[\"whiskers\"], color=color)\n",
    "    plt.setp(bp[\"caps\"], color=color)\n",
    "    plt.setp(bp[\"medians\"], color=color)\n",
    "    plt.setp(bp[\"caps\"], color=color)\n",
    "    plt.setp(bp[\"fliers\"], color=color)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(constrained_layout=True)\n",
    "fig.set_figwidth(5)\n",
    "colors = [\n",
    "    color_mapping[\"blue\"],\n",
    "    color_mapping[\"red\"],\n",
    "    color_mapping[\"grey\"],\n",
    "    color_mapping[\"yellow\"],\n",
    "    color_mapping[\"brown\"],\n",
    "    color_mapping[\"turquoise\"],\n",
    "]\n",
    "\n",
    "for idx, item in enumerate(paths):\n",
    "    ax1 = ax.boxplot(\n",
    "        df.query(\"combination==@item\")[\"cum_reward\"],\n",
    "        positions=[idx * 0.3],\n",
    "        labels=[f\"{idx+1}\"],\n",
    "    )\n",
    "    set_box_color(ax1, color=colors[idx])\n",
    "ax.set_xlabel(\"Kombination\")\n",
    "ax.set_ylabel(\"Return\")\n",
    "plt.plot([], c=color_mapping[\"blue\"], label=\"Kombination 1\")\n",
    "plt.plot([], c=color_mapping[\"red\"], label=\"Kombination 2\")\n",
    "plt.plot([], c=color_mapping[\"grey\"], label=\"Kombination 3\")\n",
    "plt.plot([], c=color_mapping[\"yellow\"], label=\"Kombination 4\")\n",
    "plt.plot([], c=color_mapping[\"brown\"], label=\"Kombination 5\")\n",
    "plt.plot([], c=color_mapping[\"turquoise\"], label=\"Kombination 6\")\n",
    "plt.legend(loc=[0.6, 0.1])\n",
    "fig.savefig(\n",
    "    f\"src/main/rl/evaluation/plot_results/phase3_return_by_combi_box.png\",\n",
    "    format=\"png\",\n",
    "    dpi=300,\n",
    ")\n",
    "plt.show()\n",
    "# Welsch Ttest\n",
    "t_test_combi3_4 = ttest_ind(\n",
    "    df.query(\"combination==@paths[2]\")[\"cum_reward\"],\n",
    "    df.query(\"combination==@paths[3]\")[\"cum_reward\"],\n",
    "    equal_var=False,\n",
    ")\n",
    "print(t_test_combi3_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620f2607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create boxplots with cricticality score\n",
    "\n",
    "fig, ax = plt.subplots(constrained_layout=True)\n",
    "fig.set_figwidth(5)\n",
    "colors = [\n",
    "    color_mapping[\"blue\"],\n",
    "    color_mapping[\"red\"],\n",
    "    color_mapping[\"grey\"],\n",
    "    color_mapping[\"yellow\"],\n",
    "    color_mapping[\"brown\"],\n",
    "    color_mapping[\"turquoise\"],\n",
    "]\n",
    "\n",
    "for idx, item in enumerate(paths):\n",
    "    ax1 = ax.boxplot(\n",
    "        df.query(\"combination==@item\")[\"criticality_score\"],\n",
    "        positions=[idx * 0.3],\n",
    "        labels=[f\"{idx+1}\"],\n",
    "    )\n",
    "    set_box_color(ax1, color=colors[idx])\n",
    "ax.set_xlabel(\"Kombination\")\n",
    "ax.set_ylabel(\"Kritikalitäts-Score\")\n",
    "plt.plot([], c=color_mapping[\"blue\"], label=\"Kombination 1\")\n",
    "plt.plot([], c=color_mapping[\"red\"], label=\"Kombination 2\")\n",
    "plt.plot([], c=color_mapping[\"grey\"], label=\"Kombination 3\")\n",
    "plt.plot([], c=color_mapping[\"yellow\"], label=\"Kombination 4\")\n",
    "plt.plot([], c=color_mapping[\"brown\"], label=\"Kombination 5\")\n",
    "plt.plot([], c=color_mapping[\"turquoise\"], label=\"Kombination 6\")\n",
    "plt.legend(loc=[0.03, 0.55])\n",
    "fig.savefig(\n",
    "    f\"src/main/rl/evaluation/plot_results/phase3_return_by_combi_criticality.png\",\n",
    "    format=\"png\",\n",
    "    dpi=300,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab46735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create boxplots with combined return and cricticality score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(constrained_layout=True)\n",
    "fig.set_figwidth(5)\n",
    "colors = [\n",
    "    color_mapping[\"blue\"],\n",
    "    color_mapping[\"red\"],\n",
    "    color_mapping[\"grey\"],\n",
    "    color_mapping[\"yellow\"],\n",
    "    color_mapping[\"brown\"],\n",
    "    color_mapping[\"turquoise\"],\n",
    "]\n",
    "\n",
    "for idx, item in enumerate(paths):\n",
    "    local_df = df.query(\"combination==@item\")\n",
    "    ax1 = ax.boxplot(\n",
    "        local_df[\"criticality_score\"] + local_df[\"cum_reward\"],\n",
    "        positions=[idx * 0.3],\n",
    "        labels=[f\"{idx+1}\"],\n",
    "    )\n",
    "    set_box_color(ax1, color=colors[idx])\n",
    "ax.set_xlabel(\"Kombination\")\n",
    "ax.set_ylabel(\"Score (Kritikalitäts-Score + Return)\")\n",
    "plt.plot([], c=color_mapping[\"blue\"], label=\"Kombination 1\")\n",
    "plt.plot([], c=color_mapping[\"red\"], label=\"Kombination 2\")\n",
    "plt.plot([], c=color_mapping[\"grey\"], label=\"Kombination 3\")\n",
    "plt.plot([], c=color_mapping[\"yellow\"], label=\"Kombination 4\")\n",
    "plt.plot([], c=color_mapping[\"brown\"], label=\"Kombination 5\")\n",
    "plt.plot([], c=color_mapping[\"turquoise\"], label=\"Kombination 6\")\n",
    "plt.legend(loc=[0.61, 0.05])\n",
    "fig.savefig(\n",
    "    f\"src/main/rl/evaluation/plot_results/phase3_return_by_combi_criticality_and_return.png\",\n",
    "    format=\"png\",\n",
    "    dpi=300,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3978d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "from scipy.stats import linregress\n",
    "import numpy as np\n",
    "\n",
    "x = df[\"criticality_score\"]\n",
    "y = df[\"cum_reward\"]\n",
    "\n",
    "result = linregress(x, y)\n",
    "print(pearsonr(df[\"criticality_score\"], df[\"cum_reward\"]))\n",
    "\n",
    "plt.scatter(x, y)\n",
    "plt.plot(x, result.intercept + result.slope * x, \"r\", label=\"fitted line\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43dfbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best combinations return + criticality score\n",
    "df[df[\"cum_reward\"] + df[\"criticality_score\"] > 450][\n",
    "    [\"combination\", \"cum_reward\", \"criticality_score\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f554e801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort models by criticality score\n",
    "df[[\"criticality_score\", \"combination\"]].sort_values(\"criticality_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0387c73c-c810-42af-ad77-a7fdc9af1f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# T-tests (Welch) - only 10 models per combination no correction factor used for multiple comparisons - just to get an idea\n",
    "from scipy.stats import ttest_ind\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "test = df[[\"combination\", \"cum_reward\"]]\n",
    "\n",
    "\n",
    "wo_scen1 = test[\n",
    "    test[\"combination\"]\n",
    "    == \"src/main/rl/models/scenario1/training_04_06/scenario1_ActionSpaceOption3Wrapper_ObservationOption4Wrapper_None_RewardOption2Wrapper_TD3_training_04_06\"\n",
    "].drop(columns=[\"combination\"])\n",
    "w_scen1 = test[\n",
    "    test[\"combination\"]\n",
    "    == \"src/main/rl/models/scenario1/training_04_06/scenario1_ActionSpaceOption3Wrapper_ObservationOption5Wrapper_NPPAutomationWrapper_RewardOption2Wrapper_SAC_training_04_06\"\n",
    "].drop(columns=[\"combination\"])\n",
    "\n",
    "wo_scen2 = test[\n",
    "    test[\"combination\"]\n",
    "    == \"src/main/rl/models/scenario2/training_04_06/scenario2_ActionSpaceOption3Wrapper_ObservationOption5Wrapper_None_RewardOption2Wrapper_PPO_training_04_06\"\n",
    "].drop(columns=[\"combination\"])\n",
    "w_scen2 = test[\n",
    "    test[\"combination\"]\n",
    "    == \"src/main/rl/models/scenario2/training_04_06/scenario2_ActionSpaceOption3Wrapper_ObservationOption4Wrapper_NPPAutomationWrapper_RewardOption2Wrapper_PPO_training_04_06\"\n",
    "].drop(columns=[\"combination\"])\n",
    "\n",
    "wo_scen3 = test[\n",
    "    test[\"combination\"]\n",
    "    == \"src/main/rl/models/scenario3/training_04_06/scenario3_ActionSpaceOption3Wrapper_ObservationOption5Wrapper_None_RewardOption2Wrapper_PPO_training_04_06\"\n",
    "].drop(columns=[\"combination\"])\n",
    "w_scen3 = test[\n",
    "    test[\"combination\"]\n",
    "    == \"src/main/rl/models/scenario3/training_04_06/scenario3_ActionSpaceOption3Wrapper_ObservationOption3Wrapper_NPPAutomationWrapper_RewardOption2Wrapper_PPO_training_04_06\"\n",
    "].drop(columns=[\"combination\"])\n",
    "\n",
    "ttest_ind(wo_scen2, w_scen2, equal_var=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d00ee1d-ab1e-4f39-86fe-49f294273c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistics per combination\n",
    "from scipy.stats import iqr\n",
    "\n",
    "df_statistics_per_combination = (\n",
    "    df.drop(columns=[\"full_path\"])\n",
    "    .groupby(\n",
    "        [\n",
    "            \"combination\",\n",
    "            \"scenario\",\n",
    "            \"alg\",\n",
    "            \"action_wrapper\",\n",
    "            \"obs_wrapper\",\n",
    "            \"automation_wrapper\",\n",
    "        ],\n",
    "        dropna=False,\n",
    "    )\n",
    "    .agg([\"mean\", \"max\", \"min\", \"std\", iqr])\n",
    ")\n",
    "# Necessary to set index as alphabetical is confusing for the thesis\n",
    "df_statistics_per_combination[\"index\"] = [0, 1, 3, 2, 5, 4]\n",
    "df_statistics_per_combination = (\n",
    "    df_statistics_per_combination.reset_index()\n",
    "    .set_index([\"index\", \"combination\"])\n",
    "    .sort_index()\n",
    ")\n",
    "df_statistics_per_combination.columns = [\n",
    "    \"_\".join(a) for a in df_statistics_per_combination.columns.to_flat_index()\n",
    "]\n",
    "save_df_per_combination = df_statistics_per_combination.copy()\n",
    "[col for col in df_statistics_per_combination.columns if \"time\" in col]\n",
    "df_statistics_per_combination[\n",
    "    [\"total_timesteps_mean\", \"cum_reward_mean\", \"criticality_score_mean\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5f75d9-7ec9-494c-a70d-40e63374dddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparation to get single reward per timestamp and then mean/min/max per combiniation\n",
    "import pandas as pd\n",
    "from src.main.rl.utils.parser import parse_scenario_name, parse_wrapper\n",
    "from src.main.rl.utils.combined_parser import parse_information_from_path\n",
    "from src.main.rl.evaluation.eval import get_single_reward\n",
    "\n",
    "paths = [\n",
    "    \"src/main/rl/models/scenario1/training_04_06/scenario1_ActionSpaceOption3Wrapper_ObservationOption4Wrapper_None_RewardOption2Wrapper_TD3_training_04_06\",\n",
    "    \"src/main/rl/models/scenario1/training_04_06/scenario1_ActionSpaceOption3Wrapper_ObservationOption5Wrapper_NPPAutomationWrapper_RewardOption2Wrapper_SAC_training_04_06\",\n",
    "    \"src/main/rl/models/scenario2/training_04_06/scenario2_ActionSpaceOption3Wrapper_ObservationOption5Wrapper_None_RewardOption2Wrapper_PPO_training_04_06\",\n",
    "    \"src/main/rl/models/scenario2/training_04_06/scenario2_ActionSpaceOption3Wrapper_ObservationOption4Wrapper_NPPAutomationWrapper_RewardOption2Wrapper_PPO_training_04_06\",\n",
    "    \"src/main/rl/models/scenario3/training_04_06/scenario3_ActionSpaceOption3Wrapper_ObservationOption5Wrapper_None_RewardOption2Wrapper_PPO_training_04_06\",\n",
    "    \"src/main/rl/models/scenario3/training_04_06/scenario3_ActionSpaceOption3Wrapper_ObservationOption3Wrapper_NPPAutomationWrapper_RewardOption2Wrapper_PPO_training_04_06\",\n",
    "]\n",
    "list_combinations = [pd.DataFrame() for i in range(len(paths))]\n",
    "for idx, path in enumerate(paths):\n",
    "\n",
    "    for number in range(1, 11):\n",
    "        result_dict = {}\n",
    "        full_path = path + f\"_{str(number)}\"\n",
    "        path_to_overhand = full_path + \"/best_model.zip\"\n",
    "\n",
    "        action_wrapper, automation_wrapper, obs_wrapper, reward_wrapper = parse_wrapper(\n",
    "            full_path\n",
    "        )\n",
    "        scenario, alg, wrapper_maker = parse_information_from_path(full_path)\n",
    "        reward = get_single_reward(\n",
    "            scenario, path_to_overhand, alg, wrapper_maker, episode_length=250\n",
    "        )\n",
    "        intermediate_df = pd.DataFrame()\n",
    "        intermediate_df[full_path] = reward\n",
    "        list_combinations[idx] = list_combinations[idx].join(\n",
    "            intermediate_df, how=\"outer\"\n",
    "        )\n",
    "\n",
    "\n",
    "for idx, item in enumerate(list_combinations):\n",
    "    list_combinations[idx] = item.agg([\"mean\", \"min\", \"max\", \"std\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f187cadd-1133-4f8f-8f2d-7b92fb67c47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.main.rl.evaluation.eval import get_single_reward_sop\n",
    "\n",
    "reward_per_timestep_sop = get_single_reward_sop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b176cd-3ef3-468f-82fd-dfb6fa7e2012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot mean reward per combination per timestamp in mutiple plots with min and max\n",
    "import matplotlib.pyplot as plt\n",
    "from src.main.rl.utils.constants import color_mapping\n",
    "\n",
    "fig, ax = plt.subplots(2, 3, constrained_layout=True)\n",
    "fig.set_figheight(4)\n",
    "fig.set_figwidth(10)\n",
    "[\n",
    "    ax[0][idx].plot(item[\"mean\"], color=color_mapping[\"standard\"])\n",
    "    for idx, item in enumerate(list_combinations)\n",
    "    if idx < 3\n",
    "]\n",
    "[\n",
    "    ax[1][idx - 3].plot(item[\"mean\"], color=color_mapping[\"standard\"])\n",
    "    for idx, item in enumerate(list_combinations)\n",
    "    if idx >= 3\n",
    "]\n",
    "[\n",
    "    ax[0][idx].fill_between(\n",
    "        [i for i in range(249)],\n",
    "        item[\"min\"],\n",
    "        item[\"max\"],\n",
    "        color=color_mapping[\"standard\"],\n",
    "        alpha=0.3,\n",
    "    )\n",
    "    for idx, item in enumerate(list_combinations)\n",
    "    if idx < 3\n",
    "]\n",
    "[\n",
    "    ax[1][idx - 3].fill_between(\n",
    "        [i for i in range(249)],\n",
    "        item[\"min\"],\n",
    "        item[\"max\"],\n",
    "        color=color_mapping[\"standard\"],\n",
    "        alpha=0.3,\n",
    "    )\n",
    "    for idx, item in enumerate(list_combinations)\n",
    "    if idx >= 3\n",
    "]\n",
    "[ax[0][idx].set_xlabel(\"Zeitschritte\") for idx in range(6) if idx < 3]\n",
    "[ax[1][idx - 3].set_xlabel(\"Zeitschritte\") for idx in range(6) if idx >= 3]\n",
    "[ax[0][idx].set_ylabel(\"Value\") for idx in range(6) if idx < 3]\n",
    "[ax[1][idx - 3].set_ylabel(\"Value\") for idx in range(6) if idx >= 3]\n",
    "[ax[0][idx].set_title(f\"Kombination {idx+1}\") for idx in range(6) if idx < 3]\n",
    "[ax[1][idx - 3].set_title(f\"Kombination {idx+1}\") for idx in range(6) if idx >= 3]\n",
    "plt.show()\n",
    "fig.savefig(\n",
    "    f\"src/main/rl/evaluation/plot_results/phase3_reward_per_step_per_combi.png\",\n",
    "    format=\"png\",\n",
    "    dpi=300,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ac8359-3a55-4398-9450-42dc04869e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot mean reward per combination per timestamp in one plot\n",
    "fig, ax = plt.subplots(1, 1, constrained_layout=True)\n",
    "fig.set_figheight(4)\n",
    "fig.set_figwidth(8)\n",
    "colors = [\n",
    "    color_mapping[\"blue\"],\n",
    "    color_mapping[\"red\"],\n",
    "    color_mapping[\"grey\"],\n",
    "    color_mapping[\"yellow\"],\n",
    "    color_mapping[\"brown\"],\n",
    "    color_mapping[\"turquoise\"],\n",
    "]\n",
    "[ax.plot(item[\"mean\"], color=colors[idx]) for idx, item in enumerate(list_combinations)]\n",
    "# Activate/Deactiveate with SOP\n",
    "# ax.plot(reward_per_timestep_sop, color=\"black\")\n",
    "ax.set_xlabel(\"Zeitschritte\")\n",
    "ax.set_ylabel(\"Reward\")\n",
    "plt.plot([], c=color_mapping[\"blue\"], label=\"Kombination 1\")\n",
    "plt.plot([], c=color_mapping[\"red\"], label=\"Kombination 2\")\n",
    "plt.plot([], c=color_mapping[\"grey\"], label=\"Kombination 3\")\n",
    "plt.plot([], c=color_mapping[\"yellow\"], label=\"Kombination 4\")\n",
    "plt.plot([], c=color_mapping[\"brown\"], label=\"Kombination 5\")\n",
    "plt.plot([], c=color_mapping[\"turquoise\"], label=\"Kombination 6\")\n",
    "plt.legend()\n",
    "fig.savefig(\n",
    "    f\"src/main/rl/evaluation/plot_results/phase3_reward_per_step_per_combi.png\",\n",
    "    format=\"png\",\n",
    "    dpi=300,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7346b2dd-709b-45c1-ac7a-0c492d144d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot mean reward per combination per timestamp in mutiple plots\n",
    "import matplotlib.pyplot as plt\n",
    "from src.main.rl.utils.constants import color_mapping\n",
    "\n",
    "paths = [\n",
    "    \"src/main/rl/models/scenario1/training_04_06/scenario1_ActionSpaceOption3Wrapper_ObservationOption4Wrapper_None_RewardOption2Wrapper_TD3_training_04_06\",\n",
    "    \"src/main/rl/models/scenario1/training_04_06/scenario1_ActionSpaceOption3Wrapper_ObservationOption5Wrapper_NPPAutomationWrapper_RewardOption2Wrapper_SAC_training_04_06\",\n",
    "    \"src/main/rl/models/scenario2/training_04_06/scenario2_ActionSpaceOption3Wrapper_ObservationOption5Wrapper_None_RewardOption2Wrapper_PPO_training_04_06\",\n",
    "    \"src/main/rl/models/scenario2/training_04_06/scenario2_ActionSpaceOption3Wrapper_ObservationOption4Wrapper_NPPAutomationWrapper_RewardOption2Wrapper_PPO_training_04_06\",\n",
    "    \"src/main/rl/models/scenario3/training_04_06/scenario3_ActionSpaceOption3Wrapper_ObservationOption5Wrapper_None_RewardOption2Wrapper_PPO_training_04_06\",\n",
    "    \"src/main/rl/models/scenario3/training_04_06/scenario3_ActionSpaceOption3Wrapper_ObservationOption3Wrapper_NPPAutomationWrapper_RewardOption2Wrapper_PPO_training_04_06\",\n",
    "]\n",
    "list_combinations = [pd.DataFrame() for i in range(len(paths))]\n",
    "for idx, path in enumerate(paths):\n",
    "\n",
    "    for number in range(1, 11):\n",
    "        result_dict = {}\n",
    "        full_path = path + f\"_{str(number)}\"\n",
    "        path_to_overhand = full_path + \"/best_model.zip\"\n",
    "\n",
    "        action_wrapper, automation_wrapper, obs_wrapper, reward_wrapper = parse_wrapper(\n",
    "            full_path\n",
    "        )\n",
    "        scenario, alg, wrapper_maker = parse_information_from_path(full_path)\n",
    "        reward = get_single_reward(\n",
    "            scenario, path_to_overhand, alg, wrapper_maker, episode_length=250\n",
    "        )\n",
    "        intermediate_df = pd.DataFrame()\n",
    "        intermediate_df[full_path] = reward\n",
    "        list_combinations[idx] = list_combinations[idx].join(\n",
    "            intermediate_df, how=\"outer\"\n",
    "        )\n",
    "fig, ax = plt.subplots(2, 3, constrained_layout=True)\n",
    "fig.set_figheight(20)\n",
    "fig.set_figwidth(20)\n",
    "[\n",
    "    ax[0][idx].plot(item, color=color_mapping[\"standard\"])\n",
    "    for idx, item in enumerate(list_combinations)\n",
    "    if idx < 3\n",
    "]\n",
    "[\n",
    "    ax[1][idx - 3].plot(item, color=color_mapping[\"standard\"])\n",
    "    for idx, item in enumerate(list_combinations)\n",
    "    if idx >= 3\n",
    "]\n",
    "\n",
    "[ax[0][idx].set_xlabel(\"Zeitschritte\") for idx in range(6) if idx < 3]\n",
    "[ax[1][idx - 3].set_xlabel(\"Zeitschritte\") for idx in range(6) if idx >= 3]\n",
    "[ax[0][idx].set_ylabel(\"Value\") for idx in range(6) if idx < 3]\n",
    "[ax[1][idx - 3].set_ylabel(\"Value\") for idx in range(6) if idx >= 3]\n",
    "[ax[0][idx].set_title(f\"Kombination {idx+1}\") for idx in range(6) if idx < 3]\n",
    "[ax[1][idx - 3].set_title(f\"Kombination {list_idx+1}\") for idx in range(6) if idx >= 3]\n",
    "plt.show()\n",
    "fig.savefig(\n",
    "    f\"src/main/rl/evaluation/plot_results/phase3_reward_per_step_per_combi_2.png\",\n",
    "    format=\"png\",\n",
    "    dpi=300,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4fa513-a15b-415d-ac22-5b1fb026b4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Statistics over the all combinations and models (60 models) ######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5829420c-b42d-44e2-ab8b-6ffa161d2655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read / Create df with results of all tests in phase 3\n",
    "import pandas as pd\n",
    "from scipy.stats import iqr\n",
    "from src.main.rl.evaluation.phase3_evaluation import create_evaluation_df_phase3\n",
    "\n",
    "path_to_save = \"src/main/rl/evaluation/output/phase3_evaluation_results.csv\"\n",
    "pd.options.display.max_colwidth = 500\n",
    "df = pd.DataFrame()\n",
    "try:\n",
    "    df = pd.read_csv(path_to_save)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "if df.empty:\n",
    "    create_evaluation_df_phase3(path_to_save, paths)\n",
    "    df = pd.read_csv(path_to_save)\n",
    "df[[\"combination\", \"cum_reward\", \"criticality_score\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e51bf21-ab5c-4adf-94db-94ee5a4ba294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistics per combination\n",
    "df_statistics_per_combination = (\n",
    "    df.drop(columns=[\"full_path\"])\n",
    "    .groupby(\n",
    "        [\n",
    "            \"combination\",\n",
    "            \"scenario\",\n",
    "            \"alg\",\n",
    "            \"action_wrapper\",\n",
    "            \"obs_wrapper\",\n",
    "            \"automation_wrapper\",\n",
    "        ],\n",
    "        dropna=False,\n",
    "    )\n",
    "    .agg([\"mean\", \"max\", \"min\", \"std\", iqr])\n",
    ")\n",
    "# Necessary to set index as alphabetical is confusing for the thesis\n",
    "df_statistics_per_combination[\"index\"] = [0, 1, 3, 2, 5, 4]\n",
    "df_statistics_per_combination = (\n",
    "    df_statistics_per_combination.reset_index()\n",
    "    .set_index([\"index\", \"combination\"])\n",
    "    .sort_index()\n",
    ")\n",
    "df_statistics_per_combination.columns = [\n",
    "    \"_\".join(a) for a in df_statistics_per_combination.columns.to_flat_index()\n",
    "]\n",
    "save_df_per_combination = df_statistics_per_combination.copy()\n",
    "df_statistics_per_combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e49f539-e91a-4b18-aa88-32dcb8156637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criticality Score per combination\n",
    "print(df_statistics_per_combination[[\"criticality_score_mean\"]].round(2))\n",
    "print(\n",
    "    df_statistics_per_combination[\n",
    "        [\n",
    "            \"criticality_score_mean\",\n",
    "            \"criticality_score_max\",\n",
    "            \"criticality_score_min\",\n",
    "            \"criticality_score_std\",\n",
    "            \"criticality_score_iqr\",\n",
    "        ]\n",
    "    ]\n",
    "    .droplevel(1)\n",
    "    .transpose()\n",
    "    .round(2)\n",
    "    .to_latex()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928462a2-35ca-4b0e-92f3-a7a26d5ca325",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_statistics_per_combination[\"cum_reward_max\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
